{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from fuzzywuzzy import fuzz\n",
    "import evaluate\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import top_k_accuracy_score, ndcg_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_five_words(sentence):\n",
    "    words = sentence.split()  # Split the sentence into a list of words\n",
    "    return \" \".join(words[:10])  # Join the first 5 words back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_beauty/splits/train.jsonl\"\n",
    "df_recommender_train = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_train.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGWDYYVVWM3DC3CASUZKXK67G6IA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'burts bees marshmallow cream...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFIJLAW3HIOMRUFSWNH54IJ3XQAA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'crest whitestrips premium - ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGZZXSMMS4WRHHJRBUJZI4FZDHKQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'norelco 8894xl', 'parent_asi...</td>\n",
       "      <td>[{'product_name': 'Sunsonic Electric Razor, Re...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHNSZCP3JIOZZVYXFJRGQEKRSTFA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'crest whitestrips dental whi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGWDYYVVWM3DC3CASUZKXK67G6IA</td>\n",
       "      <td>[{'product_name': 'BURTS BEES Marshmallow Crea...</td>\n",
       "      <td>{'product_name': 'komenuka bijin all-natural e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>AEUAQ6BAUEBP2C754LR3ILYHP54Q</td>\n",
       "      <td>[{'product_name': 'Hair Straightener Flat Iron...</td>\n",
       "      <td>{'product_name': '10pcs nail tips clips for qu...</td>\n",
       "      <td>[{'product_name': '20pcs Nail Tips Clips for Q...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>AHPGHDFIU3BUB3RQBP56RQQA7W4Q</td>\n",
       "      <td>[{'product_name': '8 PCS 40ML Mini Spray Bottl...</td>\n",
       "      <td>{'product_name': 'happygo jade roller for wome...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>AGRKJRPX6I5DQPODOC4YJ7CT4XWA</td>\n",
       "      <td>[{'product_name': 'DEROL Lip Plumper, Lip Plum...</td>\n",
       "      <td>{'product_name': 'purple shampoo and condition...</td>\n",
       "      <td>[{'product_name': 'Purple Shampoo and Conditio...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>AHV6QCNBJNSGLATP56JAWJ3C4G2A</td>\n",
       "      <td>[{'product_name': 'Scrub Angel Organic Arabica...</td>\n",
       "      <td>{'product_name': 'little moon essentials tropi...</td>\n",
       "      <td>[{'product_name': 'Smooth Lavender Sugar Scrub...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>AHY2TURQPNIDXZGH2CMQLZ343YMQ</td>\n",
       "      <td>[{'product_name': 'Pretty Frank Natural Deodor...</td>\n",
       "      <td>{'product_name': 'lankiz individual lashes kit...</td>\n",
       "      <td>[{'product_name': 'Eyelash Extensions 0.15mm D...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6444 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id  \\\n",
       "0     AGWDYYVVWM3DC3CASUZKXK67G6IA   \n",
       "1     AFIJLAW3HIOMRUFSWNH54IJ3XQAA   \n",
       "2     AGZZXSMMS4WRHHJRBUJZI4FZDHKQ   \n",
       "3     AHNSZCP3JIOZZVYXFJRGQEKRSTFA   \n",
       "4     AGWDYYVVWM3DC3CASUZKXK67G6IA   \n",
       "...                            ...   \n",
       "6439  AEUAQ6BAUEBP2C754LR3ILYHP54Q   \n",
       "6440  AHPGHDFIU3BUB3RQBP56RQQA7W4Q   \n",
       "6441  AGRKJRPX6I5DQPODOC4YJ7CT4XWA   \n",
       "6442  AHV6QCNBJNSGLATP56JAWJ3C4G2A   \n",
       "6443  AHY2TURQPNIDXZGH2CMQLZ343YMQ   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4     [{'product_name': 'BURTS BEES Marshmallow Crea...   \n",
       "...                                                 ...   \n",
       "6439  [{'product_name': 'Hair Straightener Flat Iron...   \n",
       "6440  [{'product_name': '8 PCS 40ML Mini Spray Bottl...   \n",
       "6441  [{'product_name': 'DEROL Lip Plumper, Lip Plum...   \n",
       "6442  [{'product_name': 'Scrub Angel Organic Arabica...   \n",
       "6443  [{'product_name': 'Pretty Frank Natural Deodor...   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'burts bees marshmallow cream...   \n",
       "1     {'product_name': 'crest whitestrips premium - ...   \n",
       "2     {'product_name': 'norelco 8894xl', 'parent_asi...   \n",
       "3     {'product_name': 'crest whitestrips dental whi...   \n",
       "4     {'product_name': 'komenuka bijin all-natural e...   \n",
       "...                                                 ...   \n",
       "6439  {'product_name': '10pcs nail tips clips for qu...   \n",
       "6440  {'product_name': 'happygo jade roller for wome...   \n",
       "6441  {'product_name': 'purple shampoo and condition...   \n",
       "6442  {'product_name': 'little moon essentials tropi...   \n",
       "6443  {'product_name': 'lankiz individual lashes kit...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [{'product_name': 'Sunsonic Electric Razor, Re...   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "6439  [{'product_name': '20pcs Nail Tips Clips for Q...   \n",
       "6440                                                 []   \n",
       "6441  [{'product_name': 'Purple Shampoo and Conditio...   \n",
       "6442  [{'product_name': 'Smooth Lavender Sugar Scrub...   \n",
       "6443  [{'product_name': 'Eyelash Extensions 0.15mm D...   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "6439  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "6440  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "6441  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "6442  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "6443  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[6444 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_beauty/splits/val.jsonl\"\n",
    "df_recommender_validation = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_validation.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGYVC7KVHP2AWM7BDCEYNHFA6F3Q</td>\n",
       "      <td>[{'product_name': 'MD Complete Bright &amp; Health...</td>\n",
       "      <td>{'product_name': 'nohj secret repair 3d-ampoul...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFATNFWGYVVMEZWGDNLDUXRBRFLQ</td>\n",
       "      <td>[{'product_name': '16 Jars Chrome Nail Powder ...</td>\n",
       "      <td>{'product_name': '12pcs floral boho headbands ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFDYIK3FNPY2JFBQYUWC6GSBMIRQ_2</td>\n",
       "      <td>[{'product_name': 'Kaneles Long Wavy Dark Brow...</td>\n",
       "      <td>{'product_name': 'headband wig straight human ...</td>\n",
       "      <td>[{'product_name': 'Kinky Straight Headband Wig...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEID4BJMMM6LCEUTIHBUM5H4E3BQ</td>\n",
       "      <td>[{'product_name': 'Bold Men, Mens Hair Brush F...</td>\n",
       "      <td>{'product_name': 'lip plumper set, natural lip...</td>\n",
       "      <td>[{'product_name': 'Lip Plumper Set Natural Lip...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEMRAZPNN2NBBUDV4YGGYMGPFC6A</td>\n",
       "      <td>[{'product_name': 'Cleancult Soap Dispenser wi...</td>\n",
       "      <td>{'product_name': 'coppertone kids clear sunscr...</td>\n",
       "      <td>[{'product_name': 'Under Eye Ultraviolet Prote...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>AHXDPC5UCJ24S7IIS3CRJDCTOJRA</td>\n",
       "      <td>[{'product_name': 'Deep Wave Wig Natural Human...</td>\n",
       "      <td>{'product_name': 'vtaozi lace front wigs human...</td>\n",
       "      <td>[{'product_name': 'ZILING Straight Lace Front ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>AGCPEDYIF2QXKNLBIOOEKEHJ5V2A</td>\n",
       "      <td>[{'product_name': 'Gold Collagen Under Eye Pat...</td>\n",
       "      <td>{'product_name': 'cocosolis grow hair growth s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>AFTLUVGQWKW6XSQ5TB6UER5Q263A</td>\n",
       "      <td>[{'product_name': 'Stainless Steel Gua Sha Scr...</td>\n",
       "      <td>{'product_name': 'osrsr cryo sticks,unbreakabl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>AE3UKETTR77J4LM2ZE4AEUC4L6KA</td>\n",
       "      <td>[{'product_name': 'RBA’s Firming Serum to Redu...</td>\n",
       "      <td>{'product_name': 'skinesque wake up and makeup...</td>\n",
       "      <td>[{'product_name': 'Premium black caviar facial...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>AGJMUGA3ZLDJXI7HMYAZXXISE3UQ</td>\n",
       "      <td>[{'product_name': 'CIMIY Gel Nail Polish Set 8...</td>\n",
       "      <td>{'product_name': 'utrue 2pcs rhinestone headba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  \\\n",
       "0       AGYVC7KVHP2AWM7BDCEYNHFA6F3Q   \n",
       "1       AFATNFWGYVVMEZWGDNLDUXRBRFLQ   \n",
       "2     AFDYIK3FNPY2JFBQYUWC6GSBMIRQ_2   \n",
       "3       AEID4BJMMM6LCEUTIHBUM5H4E3BQ   \n",
       "4       AEMRAZPNN2NBBUDV4YGGYMGPFC6A   \n",
       "...                              ...   \n",
       "1375    AHXDPC5UCJ24S7IIS3CRJDCTOJRA   \n",
       "1376    AGCPEDYIF2QXKNLBIOOEKEHJ5V2A   \n",
       "1377    AFTLUVGQWKW6XSQ5TB6UER5Q263A   \n",
       "1378    AE3UKETTR77J4LM2ZE4AEUC4L6KA   \n",
       "1379    AGJMUGA3ZLDJXI7HMYAZXXISE3UQ   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0     [{'product_name': 'MD Complete Bright & Health...   \n",
       "1     [{'product_name': '16 Jars Chrome Nail Powder ...   \n",
       "2     [{'product_name': 'Kaneles Long Wavy Dark Brow...   \n",
       "3     [{'product_name': 'Bold Men, Mens Hair Brush F...   \n",
       "4     [{'product_name': 'Cleancult Soap Dispenser wi...   \n",
       "...                                                 ...   \n",
       "1375  [{'product_name': 'Deep Wave Wig Natural Human...   \n",
       "1376  [{'product_name': 'Gold Collagen Under Eye Pat...   \n",
       "1377  [{'product_name': 'Stainless Steel Gua Sha Scr...   \n",
       "1378  [{'product_name': 'RBA’s Firming Serum to Redu...   \n",
       "1379  [{'product_name': 'CIMIY Gel Nail Polish Set 8...   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'nohj secret repair 3d-ampoul...   \n",
       "1     {'product_name': '12pcs floral boho headbands ...   \n",
       "2     {'product_name': 'headband wig straight human ...   \n",
       "3     {'product_name': 'lip plumper set, natural lip...   \n",
       "4     {'product_name': 'coppertone kids clear sunscr...   \n",
       "...                                                 ...   \n",
       "1375  {'product_name': 'vtaozi lace front wigs human...   \n",
       "1376  {'product_name': 'cocosolis grow hair growth s...   \n",
       "1377  {'product_name': 'osrsr cryo sticks,unbreakabl...   \n",
       "1378  {'product_name': 'skinesque wake up and makeup...   \n",
       "1379  {'product_name': 'utrue 2pcs rhinestone headba...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [{'product_name': 'Kinky Straight Headband Wig...   \n",
       "3     [{'product_name': 'Lip Plumper Set Natural Lip...   \n",
       "4     [{'product_name': 'Under Eye Ultraviolet Prote...   \n",
       "...                                                 ...   \n",
       "1375  [{'product_name': 'ZILING Straight Lace Front ...   \n",
       "1376                                                 []   \n",
       "1377                                                 []   \n",
       "1378  [{'product_name': 'Premium black caviar facial...   \n",
       "1379                                                 []   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "1375  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1376  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1377  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1378  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1379  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[1380 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"google/flan-t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6444 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6444/6444 [01:09<00:00, 93.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 196\n",
      "len(prompt_train): 6248\n",
      "len(recommend_train): 6248\n"
     ]
    }
   ],
   "source": [
    "prompt_train = []\n",
    "recommend_train = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_train.iterrows(), total=len(df_recommender_train)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_train.append(prompt)\n",
    "                recommend_train.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_train): {len(prompt_train)}\")\n",
    "print(f\"len(recommend_train): {len(recommend_train)}\")\n",
    "\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_train, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_train, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_train = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1380/1380 [00:15<00:00, 91.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 64\n",
      "len(prompt_validation): 1316\n",
      "len(recommend_validation): 1316\n"
     ]
    }
   ],
   "source": [
    "prompt_validation = []\n",
    "recommend_validation = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_validation.iterrows(), total=len(df_recommender_validation)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "            \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_validation.append(prompt)\n",
    "                recommend_validation.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "        \n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_validation): {len(prompt_validation)}\")\n",
    "print(f\"len(recommend_validation): {len(recommend_validation)}\")\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_validation, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_validation, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_validation = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    input_ids, attention_mask, labels,  = [], [], []\n",
    "    for sample in batch:\n",
    "        input_ids.append(sample['input_ids'])\n",
    "        attention_mask.append(sample['attention_mask'])\n",
    "        labels.append(sample['labels'])\n",
    "    max_encoder_len = max(sum(x) for x in attention_mask)\n",
    "    max_decoder_len = max(sum([0 if item == IGNORE_INDEX else 1 for item in x]) for x in labels)\n",
    "    return {\n",
    "        'input_ids': torch.tensor(input_ids)[:, :max_encoder_len],\n",
    "        'attention_mask': torch.tensor(attention_mask)[:, :max_encoder_len],\n",
    "        'labels': torch.tensor(labels)[:, :max_decoder_len]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_beauty/T5_recommender\",\n",
    "    num_train_epochs=5,\n",
    "    # logging_steps=500,\n",
    "    # logging_dir=self.cfg.logging_dir,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=0.3,#self.cfg.save_steps,\n",
    "    eval_steps=0.3, #self.cfg.eval_steps,\n",
    "    save_total_limit=3,\n",
    "    gradient_accumulation_steps=3, #gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=4, #train_batch_size,\n",
    "    per_device_eval_batch_size=4, #self.cfg.eval_batch_size,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    # dataloader_drop_last=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_validation,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2600/2600 22:26, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.490100</td>\n",
       "      <td>2.935113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>2.760500</td>\n",
       "      <td>2.860232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>2.629700</td>\n",
       "      <td>2.851538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # resume_from_checkpoint=True\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_beauty/splits/test.jsonl\"\n",
    "df_recommender_test = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_training_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_beauty/beauty_df.csv\"\n",
    "\n",
    "all_apps = []\n",
    "with open(apps_training_path, 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        all_apps.append(get_first_five_words(row[\"title\"].lower()))\n",
    "        \n",
    "all_apps = list(set(all_apps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app = pd.read_csv(apps_training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app[\"categories\"].apply(lambda x: len(x)>2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_app[\"categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Ensure that you've already defined 'apps_training_path' to point to your data file\n",
    "cols = ['title', 'book_id', 'genres']\n",
    "df_app = pd.read_csv(apps_training_path, usecols=cols)\n",
    "df_app = df_app.drop_duplicates(subset='book_id', keep='first')\n",
    "df_apps = df_app.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "def filter_candidate_apps(rec_app_name):\n",
    "    candidate_apps = set()  # Using a set to avoid duplicates\n",
    "    df_rec_app = df_apps[df_apps['title'] == rec_app_name.lower()]\n",
    "    \n",
    "    if df_rec_app.empty:\n",
    "        print(\"No matching app found.\")\n",
    "        return []\n",
    "    \n",
    "    recommended_app_category = df_rec_app['genres'].iloc[0]\n",
    "    \n",
    "    df_same_category = df_apps[df_apps['genres'] == recommended_app_category]\n",
    "    # same category\n",
    "    if len(candidate_apps) < 25:\n",
    "        for _, row in df_same_category.iterrows():\n",
    "            if len(candidate_apps) >= 25:\n",
    "                break\n",
    "            candidate_apps.add(row['title'])\n",
    "    \n",
    "    if len(candidate_apps) < 25:\n",
    "        genre_list = [genre.strip() for genre in recommended_app_category.split(\",\") if genre.strip()]\n",
    "        while genre_list and len(candidate_apps) < 25:\n",
    "            # Randomly remove one item\n",
    "            removed_item = random.choice(genre_list)\n",
    "            genre_list.remove(removed_item)\n",
    "            \n",
    "            recommended_app_category = \", \".join(genre_list)\n",
    "            \n",
    "            df_same_category = df_apps[df_apps['genres'] == recommended_app_category]\n",
    "            for _, row in df_same_category.iterrows():\n",
    "                if len(candidate_apps) >= 25:\n",
    "                    break\n",
    "                candidate_apps.add(row['title'])\n",
    "            genre_list = [genre.strip() for genre in recommended_app_category.split(\",\") if genre.strip()]\n",
    "\n",
    "    # all\n",
    "    if len(candidate_apps) < 25:\n",
    "        for _, row in df_apps.iterrows():\n",
    "            if len(candidate_apps) >= 25:\n",
    "                break\n",
    "            candidate_apps.add(row['title'])\n",
    "\n",
    "    return list(candidate_apps)  # Converting back to list if needed for downstream processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_creator(row):\n",
    "    np.random.seed(row.name)\n",
    "    selected_values = np.random.choice(np.setdiff1d(all_apps, [get_first_five_words(row[\"recommended_product\"][\"product_name\"])]), 24, replace=False) #  \n",
    "    random_position = np.random.randint(0, len(selected_values) + 1)\n",
    "    \n",
    "    return np.insert(selected_values, random_position, get_first_five_words(row[\"recommended_product\"][\"product_name\"])) \n",
    "\n",
    "df_recommender_test['candidate'] = df_recommender_test.apply(lambda row: candidate_creator(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 68\n",
      "Number of prompt: 1314\n",
      "Number of generations: 1314\n",
      "Number of candidate apps: 1314\n",
      "Number of true candidate indexes: 1314\n"
     ]
    }
   ],
   "source": [
    "prompt_test = []\n",
    "recommend_test = []\n",
    "candidate_books = []\n",
    "true_candidate_indexes = []\n",
    "not_founds = 0\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    candidates = []\n",
    "    for index, candidate_book in enumerate(row[\"candidate\"].tolist()):\n",
    "        candidates.append(candidate_book)\n",
    "        if candidate_book == get_first_five_words(row[\"recommended_product\"][\"product_name\"]):\n",
    "            true_candidate_index = index\n",
    "    prompt = \"\"\n",
    "    \n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "        if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            prompt_test.append(prompt)\n",
    "            recommend_test.append(recommended)\n",
    "            candidate_books.append(candidates)\n",
    "            true_candidate_indexes.append(true_candidate_index)\n",
    "            found = True\n",
    "            break\n",
    "        else:\n",
    "            prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"Number of prompt: {len(prompt_test)}\")\n",
    "print(f\"Number of generations: {len(recommend_test)}\")\n",
    "print(f\"Number of candidate apps: {len(candidate_books)}\")\n",
    "print(f\"Number of true candidate indexes: {len(true_candidate_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer: Hey! What brings you by today?\\nhuman: I’m searching for liquid eyeliner. Can you suggest something?\\ncomputer: Could you share some more details about it?\\nhuman: I\\'m expecting it to be long-lasting.\\ncomputer: Do you have a favorite store or brand?\\nhuman: I am interested in items from LuminaGlow.\\ncomputer: Are you interested in popular products?\\nhuman: Popular items do not catch my eye.\\ncomputer: What type of product quality do you have in mind?\\nhuman: Product quality is absolutely important.\\ncomputer: I suggest trying out \"INGRINC Lying Silkworm Eyeliner Pen Shiny Matte Rotatable Highlighter Makeup Eyeshadow Pencil Brighten Bottom-Eyelid Silkworm Makeup Eyeshadow Eyeliner Pen for Women Girls (5)\" based on your interests.\\nhuman: I\\'ve heard that some eyeliner pens can be quite challenging to apply. Is this one easy to use?\\ncomputer: According to a number of user reviews, this eyeliner pen can indeed be challenging to apply effectively.\\nhuman: Hmm, I am not sure. I think I will try a different item.\\ncomputer: Noted. There\\'s also \"Luxsea 12 Colors Liquid Eyeliner Kit Matte and Glitter Colorful Cosmetic Pen Set Lasting Highly-Pigmented Extremely Fine Easy to Wear Waterproof Eye Liner Makeup Pen Set\". Would you like to consider it?\\nhuman: Can you tell me if this liquid eyeliner has any issues I should be aware of before I buy it?\\ncomputer: Referring to a number of user reviews, some customers have noted that it dries out quickly and has inconsistent application.\\nhuman: I think I\\'ll skip this one. I\\'m not comfortable with the reported drying out quickly and inconsistent application.\\ncomputer: Understood. Another option you might like is \"8 Color Colored Liquid Eyeliner Colorful Pen Set, Neon Green Purple White Blue Black Rainbow Colorful Matte Liquid Eyeliner Set Eye Liners for Women Waterproof Pencil delineadores de colores para ojos\". Would you like to learn more about it?\\nhuman: Can you tell me if the liquid eyeliner you\\'re recommending has any issues or negative points?\\ncomputer: Based on numerous user reviews, this liquid eyeliner is not quick-drying and smudges easily.\\nhuman: I don\\'t want an item that is not quick-drying and smudges easily. Do you have other recommendations without such issues?\\ncomputer: I would recommend the '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luminaglow liquid dual eyeliner waterproof vegan black smudge proof cruelty-free'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lucyhairwig synthetic lace front wig ombre blonde heat resistant fiber hair wigs body wave glueless lace front blonde wigs for women',\n",
       " 'temotei 2 in 1 delicate shampoo 13.5oz',\n",
       " 'fragrantshare makeup brushes professional organizer foundation brush for liquid makeup travel 9pcs sets - odorless fiber hair - light blue',\n",
       " '240 pieces extra long ballerina press on nails glitter acrylic coffin false nails full cover fake nails tips with a crystal nail file for nail art salon diy decoration (glitter)',\n",
       " 'mifengda 5 pieces crystal rhinestones hair barrettes fashion girls small crystal hairpins flower butterfly french clip vintage hair clips bridal wedding hairpins jewelry accessory for women or girls',\n",
       " 'bvendano 10×10gm face paint kit one stroke split cake water based palette with 3 professional brushes body paint makeup birthday party halloween',\n",
       " 'brazilian body wave human hair lace frontal wigs 13x4x1 t part lace front wigs for black women natural hairline 18 inches',\n",
       " 'jiaufmi makeup brush cleaning mat cosmetic brush cleaner pad silicone washing tool scrubber suction cup,rose',\n",
       " 'leyla milani hair - heat protecting anti frizz shine & thermal spray alcohol-free, clean melon scent, hair repair - glossilocks spray - msrp $23',\n",
       " 'set of 3 tongue scrapers for adult, tool cleaner against bad breath. hygiene products and oral care for fresh breath / 3 raspadores linguales, cuidado bucal para un aliento fresco',\n",
       " 'lace front wigs straight human hair silk base lace closure wigs for black women 10a brazilian remy virgin human hair wigs natural black color 16 inch',\n",
       " 'lilian fache electronic pedicure foot file with diamond crystals - electric pedi tool callus remover (no pressure required) usb re-chargeable - 1 coarse and 1 replacement xtra course head, pink',\n",
       " 'dangle chained heart dreadlock bead crystal clear loc jewelry braiding hair accessory',\n",
       " 'stamped glorious long wavy synthetic wig ombre platinum blonde wigs for women natural looking long thick wavy wig for women heat resistant fiber synthetic wig for daily use （26inch）',\n",
       " 'kinky curly headband wigs for black women short curly headband wigs with black headband 16 inches for daily party use (ombre blonde, 16 inches)',\n",
       " '6 packs large hair claw clip for women - 4.3″ jumbo hair clips strong hold hair catch barrette',\n",
       " 'vokeyla blonde short wavy wig with bangs 12 inch shoulder length synthetic cosplay wig for women none lace honey blonde with highlight purple&pink stripe pastel wig(blonde/purple&pink)',\n",
       " 'proteove loose powder - shimmery loose powder for face and body highlighter makeup, handle powder puff design, lightweight & glowing, naturally neutral',\n",
       " 'soidram preppy makeup bag nylon cosmetic bag pink stuff makeup pouch for women girls travel toiletry bag organizer cute makeup brushes storage bag with chenille letter patches',\n",
       " 'ra herbals ultimate vitamin c serum',\n",
       " 'rstyle uv gel nail polish set, 4 colors glitter light pink red gel nail polish kit uv/led manicure nail starter kit with gift box for nail art design diy at home 5ml tiny bottle',\n",
       " \"8 rolls white eyelash extension pe tape, adhesive fabric eyelash tape, lash pe tape for eyelash extension supply, 1/2'' x 10 yards\",\n",
       " 'eyebrow stamp stencil kit, double eyebrow stamp kit, perfect eyebrow powder stamp makeup with with 24 reusable eyebrow stencil,2 eyebrow brushes and 1 eyebrow trimmer (dark brown + medium brown)',\n",
       " \"aideshair short black and white wig with bangs women's wig curly wave synthetic cosplay girl colorful wig… (black and white)\",\n",
       " 'hair clips for women and girls by rioa – wide teeth & double-hinged design – alligator styling sectioning clips of professional hair salon quality - 12pack']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_books[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_beauty/T5_recommender\")\n",
    "model.eval()\n",
    "model = model.to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70):\n",
    "  prompt_batches = list(chunk(prompt_test, batch_size))\n",
    "  generation_batches = list(chunk(recommend_test, batch_size))\n",
    "\n",
    "  correctly_predicted = []\n",
    "  for prompt_batch, generation_batch in tqdm(zip(prompt_batches, generation_batches), total = len(generation_batches)):\n",
    "\n",
    "    inputs = tokenizer(prompt_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\n",
    "    generations_predicted = model.generate(input_ids=inputs[\"input_ids\"].to('cuda'), attention_mask=inputs[\"attention_mask\"].to('cuda'),\n",
    "                            max_new_tokens=32,\n",
    "                            num_beams=8,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id) # length_penalty=0.8, Set length_penalty to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "\n",
    "    decoded_generations = [tokenizer.decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generation in generations_predicted]\n",
    "    generation_batch = [generation for generation in generation_batch]\n",
    "    \n",
    "    correctly_predicted.extend([1 if fuzz.ratio(predicted, ground_truth) > threshold else 0 for predicted, ground_truth in zip(decoded_generations, generation_batch)])\n",
    "\n",
    "  return correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [03:24<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.03881278538812785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "    \n",
    "def convert_to_sublists(numbers, sublist_size):\n",
    "    return [numbers[i:i+sublist_size] for i in range(0, len(numbers), sublist_size)]\n",
    "\n",
    "def recommender_rank(prompts, candidate_apps, model, tokenizer, batch_size=8):\n",
    "  model.eval()\n",
    "  encoder_max_length = 1024\n",
    "  decoder_max_length = 32\n",
    "  prompts_tokenized = tokenizer(prompts, max_length=encoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "  \n",
    "  input_ids_decoder = []\n",
    "  attention_mask_decoder = []\n",
    "  input_ids_encoder = []\n",
    "  attention_mask_encoder  = []\n",
    "  for index, candidate_app_elements in enumerate(candidate_apps):\n",
    "    candidate_app_elements = [tokenizer.pad_token+element for element in candidate_app_elements] # adding pad token to the beginning of each candidate app\n",
    "    candidate_apps_tokenized = tokenizer(candidate_app_elements, max_length=decoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    for candidate_app_index in range(len(candidate_app_elements)):\n",
    "      input_ids_decoder.append(candidate_apps_tokenized[\"input_ids\"][candidate_app_index])\n",
    "      attention_mask_decoder.append(candidate_apps_tokenized[\"attention_mask\"][candidate_app_index])\n",
    "      input_ids_encoder.append(prompts_tokenized[\"input_ids\"][index])\n",
    "      attention_mask_encoder.append(prompts_tokenized[\"attention_mask\"][index])\n",
    "  \n",
    "  input_ids_encoder_batches = list(chunk(input_ids_encoder, batch_size))\n",
    "  attention_mask_encoder_batches = list(chunk(attention_mask_encoder, batch_size))\n",
    "  input_ids_decoder_batches = list(chunk(input_ids_decoder, batch_size))\n",
    "  attention_mask_decoder_batches = list(chunk(attention_mask_decoder, batch_size))\n",
    "  \n",
    "\n",
    "  scores = []\n",
    "  for input_ids_encoder_batch, attention_mask_encoder_batch, input_ids_decoder_batch, attention_mask_decoder_batch in tqdm(zip(input_ids_encoder_batches, attention_mask_encoder_batches, input_ids_decoder_batches, attention_mask_decoder_batches), total = len(input_ids_encoder_batches)):\n",
    "    decoder_input_ids = torch.stack(input_ids_decoder_batch).to(\"cuda\")\n",
    "    decoder_attention_mask = torch.stack(attention_mask_decoder_batch).to(\"cuda\")\n",
    "    input_ids = torch.stack(input_ids_encoder_batch).to(\"cuda\")\n",
    "    attention_mask = torch.stack(attention_mask_encoder_batch).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "      model_output = model(decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask, \n",
    "                           input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logprobs = F.log_softmax(model_output[\"logits\"], dim=-1)[:, :-1, :] # remove the eos token\n",
    "    output_tokens = decoder_input_ids[:, 1:] # remove the bos token\n",
    "        \n",
    "    tokens_logprobs = torch.gather(logprobs, 2, output_tokens[:, :, None]).squeeze(-1).to(torch.float32)\n",
    "        \n",
    "    mask = torch.ones(tokens_logprobs.shape, dtype=torch.bool, device=\"cuda\")\n",
    "    for i, _output in enumerate(output_tokens):\n",
    "      for j, _token in enumerate(_output):\n",
    "        if _token == tokenizer.pad_token_id:\n",
    "          mask[i, j] = False\n",
    "              \n",
    "    score = (tokens_logprobs * mask).sum(-1) / mask.sum(-1)\n",
    "    scores.extend(score.to('cpu').tolist())\n",
    "    \n",
    "  # batch_input_representations = torch.cat(batch_input_representations)\n",
    "  \n",
    "  scores = convert_to_sublists(scores, len(candidate_apps[0]))\n",
    "  \n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4107/4107 [15:25<00:00,  4.44it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = recommender_rank(prompt_test, candidate_books, model, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampled Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.4368340943683409),\n",
       " np.float64(0.563165905631659),\n",
       " np.float64(0.6377473363774734),\n",
       " np.float64(0.6948249619482496),\n",
       " np.float64(0.7404870624048706),\n",
       " np.float64(0.7663622526636226),\n",
       " np.float64(0.7945205479452054),\n",
       " np.float64(0.8249619482496194),\n",
       " np.float64(0.8462709284627092),\n",
       " np.float64(0.8645357686453576)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.4368340943683409),\n",
       " np.float64(0.5165405929169422),\n",
       " np.float64(0.5538313082898493),\n",
       " np.float64(0.578413303613673),\n",
       " np.float64(0.5960778153595425),\n",
       " np.float64(0.6052947440974975),\n",
       " np.float64(0.6146808425246918),\n",
       " np.float64(0.6242840351209088),\n",
       " np.float64(0.6306986773420591),\n",
       " np.float64(0.6359784001971803)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
