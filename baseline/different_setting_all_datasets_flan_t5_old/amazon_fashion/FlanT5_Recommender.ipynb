{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from fuzzywuzzy import fuzz\n",
    "import evaluate\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import top_k_accuracy_score, ndcg_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_five_words(sentence):\n",
    "    words = sentence.split()  # Split the sentence into a list of words\n",
    "    return \" \".join(words[:10])  # Join the first 5 words back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_fashion/splits/train.jsonl\"\n",
    "df_recommender_train = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_train.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGI3EZWWHBQJAOF3UP2USMJQHIIQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'tamarac by slippers internat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGMWACNMAG74AXBF7IJ22IOZSZPA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'jansport odyssey backpack (r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF52LUUKLAOPKZCIH7N5OY5FVSVQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'dan's jewelers dolphin cross...</td>\n",
       "      <td>[{'product_name': 'Natural A Grade Golden Tige...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF52LUUKLAOPKZCIH7N5OY5FVSVQ</td>\n",
       "      <td>[{'product_name': 'Dan's Jewelers Dolphin Cros...</td>\n",
       "      <td>{'product_name': 'dan's jewelers ouroboros inf...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHWJGIMDAMS4WBLZAGOYMXYDSDLA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'glamorise wonderwire seamles...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>AEKAQSRPL77VARYBBVHZUN2AGXIQ</td>\n",
       "      <td>[{'product_name': 'Selene Women's Comfort Paja...</td>\n",
       "      <td>{'product_name': 'habiller women's cotton red ...</td>\n",
       "      <td>[{'product_name': 'Foxnovo Fashion Korean Styl...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>AEKAQSRPL77VARYBBVHZUN2AGXIQ</td>\n",
       "      <td>[{'product_name': 'Habiller Women's Cotton Red...</td>\n",
       "      <td>{'product_name': 'mehepburn women's 100% silk ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>AHRGTIMQO47C2VLJILIDU53BQKSA</td>\n",
       "      <td>[{'product_name': 'Dearfoams Women's Perforate...</td>\n",
       "      <td>{'product_name': 'hawaiian shirt 10 mens hibis...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>AERK3J6CUM2VUBJAWXI7CRK3VW6A</td>\n",
       "      <td>[{'product_name': 'YMI Juniors Super Soft Fade...</td>\n",
       "      <td>{'product_name': 'women lift nipplecovers-nipp...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>AG2EDYAYS462TLBNMXFKDFEOZWBQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'admiral', 'parent_asin': 'B0...</td>\n",
       "      <td>[{'product_name': 'b.o.c. Women's Nayarit Viny...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8925 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id  \\\n",
       "0     AGI3EZWWHBQJAOF3UP2USMJQHIIQ   \n",
       "1     AGMWACNMAG74AXBF7IJ22IOZSZPA   \n",
       "2     AF52LUUKLAOPKZCIH7N5OY5FVSVQ   \n",
       "3     AF52LUUKLAOPKZCIH7N5OY5FVSVQ   \n",
       "4     AHWJGIMDAMS4WBLZAGOYMXYDSDLA   \n",
       "...                            ...   \n",
       "8920  AEKAQSRPL77VARYBBVHZUN2AGXIQ   \n",
       "8921  AEKAQSRPL77VARYBBVHZUN2AGXIQ   \n",
       "8922  AHRGTIMQO47C2VLJILIDU53BQKSA   \n",
       "8923  AERK3J6CUM2VUBJAWXI7CRK3VW6A   \n",
       "8924  AG2EDYAYS462TLBNMXFKDFEOZWBQ   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3     [{'product_name': 'Dan's Jewelers Dolphin Cros...   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "8920  [{'product_name': 'Selene Women's Comfort Paja...   \n",
       "8921  [{'product_name': 'Habiller Women's Cotton Red...   \n",
       "8922  [{'product_name': 'Dearfoams Women's Perforate...   \n",
       "8923  [{'product_name': 'YMI Juniors Super Soft Fade...   \n",
       "8924                                                 []   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'tamarac by slippers internat...   \n",
       "1     {'product_name': 'jansport odyssey backpack (r...   \n",
       "2     {'product_name': 'dan's jewelers dolphin cross...   \n",
       "3     {'product_name': 'dan's jewelers ouroboros inf...   \n",
       "4     {'product_name': 'glamorise wonderwire seamles...   \n",
       "...                                                 ...   \n",
       "8920  {'product_name': 'habiller women's cotton red ...   \n",
       "8921  {'product_name': 'mehepburn women's 100% silk ...   \n",
       "8922  {'product_name': 'hawaiian shirt 10 mens hibis...   \n",
       "8923  {'product_name': 'women lift nipplecovers-nipp...   \n",
       "8924  {'product_name': 'admiral', 'parent_asin': 'B0...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2     [{'product_name': 'Natural A Grade Golden Tige...   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "8920  [{'product_name': 'Foxnovo Fashion Korean Styl...   \n",
       "8921                                                 []   \n",
       "8922                                                 []   \n",
       "8923                                                 []   \n",
       "8924  [{'product_name': 'b.o.c. Women's Nayarit Viny...   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "8920  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8921  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8922  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8923  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8924  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[8925 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_fashion/splits/val.jsonl\"\n",
    "df_recommender_validation = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_validation.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE364KC27KS42K7QLRHMKSZNWT5A</td>\n",
       "      <td>[{'product_name': 'Latuza Women's Sleep Tank T...</td>\n",
       "      <td>{'product_name': 'women's shirts plus size sho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGWDEVAWLMIO5YS5EAHY7VT634AA</td>\n",
       "      <td>[{'product_name': 'SHOPGLAMLA Front Pocket Lac...</td>\n",
       "      <td>{'product_name': 'sweatyrocks women's loose be...</td>\n",
       "      <td>[{'product_name': 'Orchid Row Kimono Printed C...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEJJ4HTWBXN5WXB2X2NXUCIS2LFQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'hissox women's cotton jacqua...</td>\n",
       "      <td>[{'product_name': 'Forcool Women's Warm Snow S...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AH5HSMUMRJRDWBPFDQ6G3EAAOSFQ</td>\n",
       "      <td>[{'product_name': 'Wild Hazel Women's Viscose ...</td>\n",
       "      <td>{'product_name': 'charis allure women's casual...</td>\n",
       "      <td>[{'product_name': 'JJ Perfection Women's Light...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEX2G5SGVNUJJWXJ752CQFF4LDNA</td>\n",
       "      <td>[{'product_name': 'Faddare Swing Dress with Po...</td>\n",
       "      <td>{'product_name': 'womens kimono cardigan - flo...</td>\n",
       "      <td>[{'product_name': 'Akery Women's Floral Chiffo...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>AFDYIK3FNPY2JFBQYUWC6GSBMIRQ_2</td>\n",
       "      <td>[{'product_name': 'INIBUD Women Running Shorts...</td>\n",
       "      <td>{'product_name': 'aisize women's retro velvet ...</td>\n",
       "      <td>[{'product_name': 'Milumia Women's Button up S...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>AELCHJO64W7III5PDR7RURIJV5CA</td>\n",
       "      <td>[{'product_name': 'T WILKER High Waist Yoga Pa...</td>\n",
       "      <td>{'product_name': 'el-sa kids outdoor mask mout...</td>\n",
       "      <td>[{'product_name': '20 Pack Face Mask - 5 Layer...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>AEDW6RQIIHKR37N757KAPPE76KHA</td>\n",
       "      <td>[{'product_name': 'Myiaur Night Driving Glasse...</td>\n",
       "      <td>{'product_name': 'boisouey men's athletic work...</td>\n",
       "      <td>[{'product_name': 'IGEEKWELL Men's Fleece Wint...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>AEKJQLMPWARYDWN4BQXBCPML2VWQ</td>\n",
       "      <td>[{'product_name': 'SOL3 Men's Premium Insole S...</td>\n",
       "      <td>{'product_name': 'christmas headbands for wome...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>AESH4UBOA6VWZ36CIYMP4JVYPOLA</td>\n",
       "      <td>[{'product_name': 'Damissly Women's T Shirts C...</td>\n",
       "      <td>{'product_name': 'heymiss women's crewneck pul...</td>\n",
       "      <td>[{'product_name': 'True Angel Women's Scoop Ne...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  \\\n",
       "0       AE364KC27KS42K7QLRHMKSZNWT5A   \n",
       "1       AGWDEVAWLMIO5YS5EAHY7VT634AA   \n",
       "2       AEJJ4HTWBXN5WXB2X2NXUCIS2LFQ   \n",
       "3       AH5HSMUMRJRDWBPFDQ6G3EAAOSFQ   \n",
       "4       AEX2G5SGVNUJJWXJ752CQFF4LDNA   \n",
       "...                              ...   \n",
       "1907  AFDYIK3FNPY2JFBQYUWC6GSBMIRQ_2   \n",
       "1908    AELCHJO64W7III5PDR7RURIJV5CA   \n",
       "1909    AEDW6RQIIHKR37N757KAPPE76KHA   \n",
       "1910    AEKJQLMPWARYDWN4BQXBCPML2VWQ   \n",
       "1911    AESH4UBOA6VWZ36CIYMP4JVYPOLA   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0     [{'product_name': 'Latuza Women's Sleep Tank T...   \n",
       "1     [{'product_name': 'SHOPGLAMLA Front Pocket Lac...   \n",
       "2                                                    []   \n",
       "3     [{'product_name': 'Wild Hazel Women's Viscose ...   \n",
       "4     [{'product_name': 'Faddare Swing Dress with Po...   \n",
       "...                                                 ...   \n",
       "1907  [{'product_name': 'INIBUD Women Running Shorts...   \n",
       "1908  [{'product_name': 'T WILKER High Waist Yoga Pa...   \n",
       "1909  [{'product_name': 'Myiaur Night Driving Glasse...   \n",
       "1910  [{'product_name': 'SOL3 Men's Premium Insole S...   \n",
       "1911  [{'product_name': 'Damissly Women's T Shirts C...   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'women's shirts plus size sho...   \n",
       "1     {'product_name': 'sweatyrocks women's loose be...   \n",
       "2     {'product_name': 'hissox women's cotton jacqua...   \n",
       "3     {'product_name': 'charis allure women's casual...   \n",
       "4     {'product_name': 'womens kimono cardigan - flo...   \n",
       "...                                                 ...   \n",
       "1907  {'product_name': 'aisize women's retro velvet ...   \n",
       "1908  {'product_name': 'el-sa kids outdoor mask mout...   \n",
       "1909  {'product_name': 'boisouey men's athletic work...   \n",
       "1910  {'product_name': 'christmas headbands for wome...   \n",
       "1911  {'product_name': 'heymiss women's crewneck pul...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0                                                    []   \n",
       "1     [{'product_name': 'Orchid Row Kimono Printed C...   \n",
       "2     [{'product_name': 'Forcool Women's Warm Snow S...   \n",
       "3     [{'product_name': 'JJ Perfection Women's Light...   \n",
       "4     [{'product_name': 'Akery Women's Floral Chiffo...   \n",
       "...                                                 ...   \n",
       "1907  [{'product_name': 'Milumia Women's Button up S...   \n",
       "1908  [{'product_name': '20 Pack Face Mask - 5 Layer...   \n",
       "1909  [{'product_name': 'IGEEKWELL Men's Fleece Wint...   \n",
       "1910                                                 []   \n",
       "1911  [{'product_name': 'True Angel Women's Scoop Ne...   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "1907  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1908  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1909  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1910  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1911  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[1912 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"google/flan-t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8925/8925 [01:55<00:00, 77.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 169\n",
      "len(prompt_train): 8756\n",
      "len(recommend_train): 8756\n"
     ]
    }
   ],
   "source": [
    "prompt_train = []\n",
    "recommend_train = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_train.iterrows(), total=len(df_recommender_train)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_train.append(prompt)\n",
    "                recommend_train.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_train): {len(prompt_train)}\")\n",
    "print(f\"len(recommend_train): {len(recommend_train)}\")\n",
    "\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_train, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_train, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_train = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1912/1912 [00:25<00:00, 74.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 42\n",
      "len(prompt_validation): 1870\n",
      "len(recommend_validation): 1870\n"
     ]
    }
   ],
   "source": [
    "prompt_validation = []\n",
    "recommend_validation = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_validation.iterrows(), total=len(df_recommender_validation)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "            \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_validation.append(prompt)\n",
    "                recommend_validation.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "        \n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_validation): {len(prompt_validation)}\")\n",
    "print(f\"len(recommend_validation): {len(recommend_validation)}\")\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_validation, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_validation, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_validation = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    input_ids, attention_mask, labels,  = [], [], []\n",
    "    for sample in batch:\n",
    "        input_ids.append(sample['input_ids'])\n",
    "        attention_mask.append(sample['attention_mask'])\n",
    "        labels.append(sample['labels'])\n",
    "    max_encoder_len = max(sum(x) for x in attention_mask)\n",
    "    max_decoder_len = max(sum([0 if item == IGNORE_INDEX else 1 for item in x]) for x in labels)\n",
    "    return {\n",
    "        'input_ids': torch.tensor(input_ids)[:, :max_encoder_len],\n",
    "        'attention_mask': torch.tensor(attention_mask)[:, :max_encoder_len],\n",
    "        'labels': torch.tensor(labels)[:, :max_decoder_len]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_fashion/T5_recommender\",\n",
    "    num_train_epochs=5,\n",
    "    # logging_steps=500,\n",
    "    # logging_dir=self.cfg.logging_dir,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=0.3,#self.cfg.save_steps,\n",
    "    eval_steps=0.3, #self.cfg.eval_steps,\n",
    "    save_total_limit=3,\n",
    "    gradient_accumulation_steps=3, #gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=4, #train_batch_size,\n",
    "    per_device_eval_batch_size=4, #self.cfg.eval_batch_size,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    # dataloader_drop_last=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_validation,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3645' max='3645' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3645/3645 31:32, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1094</td>\n",
       "      <td>3.171500</td>\n",
       "      <td>2.987803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2188</td>\n",
       "      <td>2.930300</td>\n",
       "      <td>2.895152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3282</td>\n",
       "      <td>2.831600</td>\n",
       "      <td>2.891896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # resume_from_checkpoint=True\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_fashion/splits/test.jsonl\"\n",
    "df_recommender_test = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_training_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_fashion/fashion_df.csv\"\n",
    "\n",
    "all_apps = []\n",
    "with open(apps_training_path, 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        all_apps.append(get_first_five_words(row[\"title\"].lower()))\n",
    "        \n",
    "all_apps = list(set(all_apps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_creator(row):\n",
    "    np.random.seed(row.name)\n",
    "    selected_values = np.random.choice(np.setdiff1d( all_apps, [get_first_five_words(row[\"recommended_product\"][\"product_name\"])]), 24, replace=False) # filter_candidate_apps(row[\"recommended_book\"][\"book_name\"])\n",
    "    random_position = np.random.randint(0, len(selected_values) + 1)\n",
    "    \n",
    "    return np.insert(selected_values, random_position, get_first_five_words(row[\"recommended_product\"][\"product_name\"])) \n",
    "\n",
    "df_recommender_test['candidate'] = df_recommender_test.apply(lambda row: candidate_creator(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 56\n",
      "Number of prompt: 1858\n",
      "Number of generations: 1858\n",
      "Number of candidate apps: 1858\n",
      "Number of true candidate indexes: 1858\n"
     ]
    }
   ],
   "source": [
    "prompt_test = []\n",
    "recommend_test = []\n",
    "candidate_books = []\n",
    "true_candidate_indexes = []\n",
    "not_founds = 0\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    candidates = []\n",
    "    for index, candidate_book in enumerate(row[\"candidate\"].tolist()):\n",
    "        candidates.append(candidate_book)\n",
    "        if candidate_book == get_first_five_words(row[\"recommended_product\"][\"product_name\"]):\n",
    "            true_candidate_index = index\n",
    "    prompt = \"\"\n",
    "    \n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "        if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            prompt_test.append(prompt)\n",
    "            recommend_test.append(recommended)\n",
    "            candidate_books.append(candidates)\n",
    "            true_candidate_indexes.append(true_candidate_index)\n",
    "            found = True\n",
    "            break\n",
    "        else:\n",
    "            prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"Number of prompt: {len(prompt_test)}\")\n",
    "print(f\"Number of generations: {len(recommend_test)}\")\n",
    "print(f\"Number of candidate apps: {len(candidate_books)}\")\n",
    "print(f\"Number of true candidate indexes: {len(true_candidate_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_fashion/T5_recommender\")\n",
    "model.eval()\n",
    "model = model.to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70):\n",
    "  prompt_batches = list(chunk(prompt_test, batch_size))\n",
    "  generation_batches = list(chunk(recommend_test, batch_size))\n",
    "\n",
    "  correctly_predicted = []\n",
    "  for prompt_batch, generation_batch in tqdm(zip(prompt_batches, generation_batches), total = len(generation_batches)):\n",
    "\n",
    "    inputs = tokenizer(prompt_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\n",
    "    generations_predicted = model.generate(input_ids=inputs[\"input_ids\"].to('cuda'), attention_mask=inputs[\"attention_mask\"].to('cuda'),\n",
    "                            max_new_tokens=32,\n",
    "                            num_beams=8,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id) # length_penalty=0.8, Set length_penalty to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "\n",
    "    decoded_generations = [tokenizer.decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generation in generations_predicted]\n",
    "    generation_batch = [generation for generation in generation_batch]\n",
    "    \n",
    "    correctly_predicted.extend([1 if fuzz.ratio(predicted, ground_truth) > threshold else 0 for predicted, ground_truth in zip(decoded_generations, generation_batch)])\n",
    "\n",
    "  return correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/233 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233/233 [04:57<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.013455328310010764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "    \n",
    "def convert_to_sublists(numbers, sublist_size):\n",
    "    return [numbers[i:i+sublist_size] for i in range(0, len(numbers), sublist_size)]\n",
    "\n",
    "def recommender_rank(prompts, candidate_apps, model, tokenizer, batch_size=8):\n",
    "  model.eval()\n",
    "  encoder_max_length = 1024\n",
    "  decoder_max_length = 32\n",
    "  prompts_tokenized = tokenizer(prompts, max_length=encoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "  \n",
    "  input_ids_decoder = []\n",
    "  attention_mask_decoder = []\n",
    "  input_ids_encoder = []\n",
    "  attention_mask_encoder  = []\n",
    "  for index, candidate_app_elements in enumerate(candidate_apps):\n",
    "    candidate_app_elements = [tokenizer.pad_token+element for element in candidate_app_elements] # adding pad token to the beginning of each candidate app\n",
    "    candidate_apps_tokenized = tokenizer(candidate_app_elements, max_length=decoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    for candidate_app_index in range(len(candidate_app_elements)):\n",
    "      input_ids_decoder.append(candidate_apps_tokenized[\"input_ids\"][candidate_app_index])\n",
    "      attention_mask_decoder.append(candidate_apps_tokenized[\"attention_mask\"][candidate_app_index])\n",
    "      input_ids_encoder.append(prompts_tokenized[\"input_ids\"][index])\n",
    "      attention_mask_encoder.append(prompts_tokenized[\"attention_mask\"][index])\n",
    "  \n",
    "  input_ids_encoder_batches = list(chunk(input_ids_encoder, batch_size))\n",
    "  attention_mask_encoder_batches = list(chunk(attention_mask_encoder, batch_size))\n",
    "  input_ids_decoder_batches = list(chunk(input_ids_decoder, batch_size))\n",
    "  attention_mask_decoder_batches = list(chunk(attention_mask_decoder, batch_size))\n",
    "  \n",
    "\n",
    "  scores = []\n",
    "  for input_ids_encoder_batch, attention_mask_encoder_batch, input_ids_decoder_batch, attention_mask_decoder_batch in tqdm(zip(input_ids_encoder_batches, attention_mask_encoder_batches, input_ids_decoder_batches, attention_mask_decoder_batches), total = len(input_ids_encoder_batches)):\n",
    "    decoder_input_ids = torch.stack(input_ids_decoder_batch).to(\"cuda\")\n",
    "    decoder_attention_mask = torch.stack(attention_mask_decoder_batch).to(\"cuda\")\n",
    "    input_ids = torch.stack(input_ids_encoder_batch).to(\"cuda\")\n",
    "    attention_mask = torch.stack(attention_mask_encoder_batch).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "      model_output = model(decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask, \n",
    "                           input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logprobs = F.log_softmax(model_output[\"logits\"], dim=-1)[:, :-1, :] # remove the eos token\n",
    "    output_tokens = decoder_input_ids[:, 1:] # remove the bos token\n",
    "        \n",
    "    tokens_logprobs = torch.gather(logprobs, 2, output_tokens[:, :, None]).squeeze(-1).to(torch.float32)\n",
    "        \n",
    "    mask = torch.ones(tokens_logprobs.shape, dtype=torch.bool, device=\"cuda\")\n",
    "    for i, _output in enumerate(output_tokens):\n",
    "      for j, _token in enumerate(_output):\n",
    "        if _token == tokenizer.pad_token_id:\n",
    "          mask[i, j] = False\n",
    "              \n",
    "    score = (tokens_logprobs * mask).sum(-1) / mask.sum(-1)\n",
    "    scores.extend(score.to('cpu').tolist())\n",
    "    \n",
    "  # batch_input_representations = torch.cat(batch_input_representations)\n",
    "  \n",
    "  scores = convert_to_sublists(scores, len(candidate_apps[0]))\n",
    "  \n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5807/5807 [21:47<00:00,  4.44it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = recommender_rank(prompt_test, candidate_books, model, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampled Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.32723358449946177),\n",
       " np.float64(0.4418729817007535),\n",
       " np.float64(0.5220667384284177),\n",
       " np.float64(0.5882669537136707),\n",
       " np.float64(0.6431646932185145),\n",
       " np.float64(0.6980624327233584),\n",
       " np.float64(0.7427341227125942),\n",
       " np.float64(0.7766415500538213),\n",
       " np.float64(0.8191603875134553),\n",
       " np.float64(0.852529601722282)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is the one\n",
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.32723358449946177),\n",
       " np.float64(0.3995629911252532),\n",
       " np.float64(0.43965986948908525),\n",
       " np.float64(0.4681707503518556),\n",
       " np.float64(0.4894080949901351),\n",
       " np.float64(0.5089630643577445),\n",
       " np.float64(0.5238536276874898),\n",
       " np.float64(0.534550230075811),\n",
       " np.float64(0.5473496755319222),\n",
       " np.float64(0.5569955416415612)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is the one\n",
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
