{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from fuzzywuzzy import fuzz\n",
    "import evaluate\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import top_k_accuracy_score, ndcg_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_five_words(sentence):\n",
    "    words = sentence.split()  # Split the sentence into a list of words\n",
    "    return \" \".join(words[:10])  # Join the first 5 words back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_garden/splits/train.jsonl\"\n",
    "df_recommender_train = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_train.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFVJZUNAWT6ZLSES4FT3AYBXCJKA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'lodge pre-seasoned cast iron...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEDYOQKGVEHNISQYBMND2ZZHYPDA</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'weber 825020 22 performer ch...</td>\n",
       "      <td>[{'product_name': 'Char-Broil 463377319 Perfor...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFWA2KTWWVNOP7T2EYX6VAOIGKEQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'char- broil standard portabl...</td>\n",
       "      <td>[{'product_name': 'Char-Broil Classic 280 2-Bu...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEJ6HUUENHAFSSJTEOI4MVNQJZ4A</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'great states 304-14 14-inch ...</td>\n",
       "      <td>[{'product_name': 'Sun Joe MJ500M 16-Inch Manu...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGYZ3XAFPLGM3Z5KITKKKU4HJQKQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'weber chimney starter', 'par...</td>\n",
       "      <td>[{'product_name': 'homenote Rapid Charcoal Chi...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>AEQFUXVWNBKN3OWA6GBT54FPS4RQ</td>\n",
       "      <td>[{'product_name': 'Weber 6678 Large Original G...</td>\n",
       "      <td>{'product_name': 'nocry home &amp; gardening knee ...</td>\n",
       "      <td>[{'product_name': 'InSassy Garden Kneeler Pad ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>AGJDABOTXPJY6M42ECWU2UHMILPQ</td>\n",
       "      <td>[{'product_name': 'VIVOSUN 6.5 Inch Gardening ...</td>\n",
       "      <td>{'product_name': 'super soil autoflower concen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>AFNKT54HHGQTCFS3GHYMTMTGOTJQ</td>\n",
       "      <td>[{'product_name': 'LogOX Hauler Ergonomic Log ...</td>\n",
       "      <td>{'product_name': 'foxfarm fx14106 752289794056...</td>\n",
       "      <td>[{'product_name': 'Compare-N-Save Concentrate ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>AHA3CPCZ66UFSEY5AWC4OHWMHTYA</td>\n",
       "      <td>[{'product_name': 'HOLDPEAK Digital Anemometer...</td>\n",
       "      <td>{'product_name': 'scotts turf builder weed &amp; f...</td>\n",
       "      <td>[{'product_name': 'Scotts Turf Builder Halts C...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>AFL6OETTJJ5W6NTHGPAMFYNV7EKA</td>\n",
       "      <td>[{'product_name': 'Kentucky 31 K31 Tall Fescue...</td>\n",
       "      <td>{'product_name': 'cesun 1 ft metal garden hose...</td>\n",
       "      <td>[{'product_name': 'Heavy Duty Flexible Hose,3/...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8533 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id  \\\n",
       "0     AFVJZUNAWT6ZLSES4FT3AYBXCJKA   \n",
       "1     AEDYOQKGVEHNISQYBMND2ZZHYPDA   \n",
       "2     AFWA2KTWWVNOP7T2EYX6VAOIGKEQ   \n",
       "3     AEJ6HUUENHAFSSJTEOI4MVNQJZ4A   \n",
       "4     AGYZ3XAFPLGM3Z5KITKKKU4HJQKQ   \n",
       "...                            ...   \n",
       "8528  AEQFUXVWNBKN3OWA6GBT54FPS4RQ   \n",
       "8529  AGJDABOTXPJY6M42ECWU2UHMILPQ   \n",
       "8530  AFNKT54HHGQTCFS3GHYMTMTGOTJQ   \n",
       "8531  AHA3CPCZ66UFSEY5AWC4OHWMHTYA   \n",
       "8532  AFL6OETTJJ5W6NTHGPAMFYNV7EKA   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "8528  [{'product_name': 'Weber 6678 Large Original G...   \n",
       "8529  [{'product_name': 'VIVOSUN 6.5 Inch Gardening ...   \n",
       "8530  [{'product_name': 'LogOX Hauler Ergonomic Log ...   \n",
       "8531  [{'product_name': 'HOLDPEAK Digital Anemometer...   \n",
       "8532  [{'product_name': 'Kentucky 31 K31 Tall Fescue...   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'lodge pre-seasoned cast iron...   \n",
       "1     {'product_name': 'weber 825020 22 performer ch...   \n",
       "2     {'product_name': 'char- broil standard portabl...   \n",
       "3     {'product_name': 'great states 304-14 14-inch ...   \n",
       "4     {'product_name': 'weber chimney starter', 'par...   \n",
       "...                                                 ...   \n",
       "8528  {'product_name': 'nocry home & gardening knee ...   \n",
       "8529  {'product_name': 'super soil autoflower concen...   \n",
       "8530  {'product_name': 'foxfarm fx14106 752289794056...   \n",
       "8531  {'product_name': 'scotts turf builder weed & f...   \n",
       "8532  {'product_name': 'cesun 1 ft metal garden hose...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0                                                    []   \n",
       "1     [{'product_name': 'Char-Broil 463377319 Perfor...   \n",
       "2     [{'product_name': 'Char-Broil Classic 280 2-Bu...   \n",
       "3     [{'product_name': 'Sun Joe MJ500M 16-Inch Manu...   \n",
       "4     [{'product_name': 'homenote Rapid Charcoal Chi...   \n",
       "...                                                 ...   \n",
       "8528  [{'product_name': 'InSassy Garden Kneeler Pad ...   \n",
       "8529                                                 []   \n",
       "8530  [{'product_name': 'Compare-N-Save Concentrate ...   \n",
       "8531  [{'product_name': 'Scotts Turf Builder Halts C...   \n",
       "8532  [{'product_name': 'Heavy Duty Flexible Hose,3/...   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "8528  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8529  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8530  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8531  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "8532  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[8533 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_garden/splits/val.jsonl\"\n",
    "df_recommender_validation = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_validation.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_previous_interactions</th>\n",
       "      <th>recommended_product</th>\n",
       "      <th>negative_recommended_product</th>\n",
       "      <th>turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFK66DCACOXFTGEPCH6VOZFPRSCQ</td>\n",
       "      <td>[{'product_name': 'HH-Eason 6 pcs Micro Landsc...</td>\n",
       "      <td>{'product_name': 'suncast 22 gallon indoor or ...</td>\n",
       "      <td>[{'product_name': 'Keter City 30 Gallon Resin ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGYUZAAY3Z7HYBSQRUPCOUQUZFZQ</td>\n",
       "      <td>[{'product_name': 'ANLEY Fly Breeze 3x5 Foot U...</td>\n",
       "      <td>{'product_name': 'vivosun 6 mil mylar film rol...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGL4MJX4J7RXZDV7LVEZKHLUW7AQ</td>\n",
       "      <td>[{'product_name': 'Gardzen 72 Pcs 5 Inch Plast...</td>\n",
       "      <td>{'product_name': 'torro products 4 pack mole r...</td>\n",
       "      <td>[{'product_name': 'YARDEC Gopher Repellent Ult...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG2VO5ZRX6FC42TZMI37IFUAUYCQ</td>\n",
       "      <td>[{'product_name': 'Juegoal 2 Pack Hummingbird ...</td>\n",
       "      <td>{'product_name': 'champion 8000-watt dual fuel...</td>\n",
       "      <td>[{'product_name': 'Westinghouse Outdoor Power ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHQ2AHLHIS6UWQJXYNP4SQ6HS2EA</td>\n",
       "      <td>[{'product_name': 'BioAdvanced Complete Insect...</td>\n",
       "      <td>{'product_name': 'foxfarm fx14019 fertilizer, ...</td>\n",
       "      <td>[{'product_name': 'Premium Water Soluble Ferti...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>AGVYLUBF4ETB5QKKEKIZLSNVD6SQ</td>\n",
       "      <td>[{'product_name': 'Terro T1700SR 2 Pack 19 oz ...</td>\n",
       "      <td>{'product_name': 'honda eu2200itag 2200-watt 1...</td>\n",
       "      <td>[{'product_name': 'Honda 664240 EU2200i 2200 W...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>AGLTUGLIGJQL4RUKOEBDOVN5MLEQ</td>\n",
       "      <td>[{'product_name': 'Fiskars Micro-Tip Pruning S...</td>\n",
       "      <td>{'product_name': 'wanapure 25pcs copper metal ...</td>\n",
       "      <td>[{'product_name': 'Vktech 5000pcs 6 x10cm Plas...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>AH43BYN2DG2EJXREWJ6NZBKORJNQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'product_name': 'j r peters 52024 jacks class...</td>\n",
       "      <td>[{'product_name': 'J R Peters Jacks Classic No...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>AH43BYN2DG2EJXREWJ6NZBKORJNQ</td>\n",
       "      <td>[{'product_name': 'J R Peters 52024 Jacks Clas...</td>\n",
       "      <td>{'product_name': 'jack's classic 10-30-20 blos...</td>\n",
       "      <td>[{'product_name': 'Neptune's Harvest Tomato &amp; ...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>AF2KCWQXYHMALI5RQYD4PAEYR5SA</td>\n",
       "      <td>[{'product_name': 'API Heated Birdbath Heated ...</td>\n",
       "      <td>{'product_name': 'antonki room thermometer ind...</td>\n",
       "      <td>[{'product_name': 'La Crosse Technology TX141T...</td>\n",
       "      <td>[{'turn': 1, 'is_rec': False, 'user_accept_rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1828 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id  \\\n",
       "0     AFK66DCACOXFTGEPCH6VOZFPRSCQ   \n",
       "1     AGYUZAAY3Z7HYBSQRUPCOUQUZFZQ   \n",
       "2     AGL4MJX4J7RXZDV7LVEZKHLUW7AQ   \n",
       "3     AG2VO5ZRX6FC42TZMI37IFUAUYCQ   \n",
       "4     AHQ2AHLHIS6UWQJXYNP4SQ6HS2EA   \n",
       "...                            ...   \n",
       "1823  AGVYLUBF4ETB5QKKEKIZLSNVD6SQ   \n",
       "1824  AGLTUGLIGJQL4RUKOEBDOVN5MLEQ   \n",
       "1825  AH43BYN2DG2EJXREWJ6NZBKORJNQ   \n",
       "1826  AH43BYN2DG2EJXREWJ6NZBKORJNQ   \n",
       "1827  AF2KCWQXYHMALI5RQYD4PAEYR5SA   \n",
       "\n",
       "                             user_previous_interactions  \\\n",
       "0     [{'product_name': 'HH-Eason 6 pcs Micro Landsc...   \n",
       "1     [{'product_name': 'ANLEY Fly Breeze 3x5 Foot U...   \n",
       "2     [{'product_name': 'Gardzen 72 Pcs 5 Inch Plast...   \n",
       "3     [{'product_name': 'Juegoal 2 Pack Hummingbird ...   \n",
       "4     [{'product_name': 'BioAdvanced Complete Insect...   \n",
       "...                                                 ...   \n",
       "1823  [{'product_name': 'Terro T1700SR 2 Pack 19 oz ...   \n",
       "1824  [{'product_name': 'Fiskars Micro-Tip Pruning S...   \n",
       "1825                                                 []   \n",
       "1826  [{'product_name': 'J R Peters 52024 Jacks Clas...   \n",
       "1827  [{'product_name': 'API Heated Birdbath Heated ...   \n",
       "\n",
       "                                    recommended_product  \\\n",
       "0     {'product_name': 'suncast 22 gallon indoor or ...   \n",
       "1     {'product_name': 'vivosun 6 mil mylar film rol...   \n",
       "2     {'product_name': 'torro products 4 pack mole r...   \n",
       "3     {'product_name': 'champion 8000-watt dual fuel...   \n",
       "4     {'product_name': 'foxfarm fx14019 fertilizer, ...   \n",
       "...                                                 ...   \n",
       "1823  {'product_name': 'honda eu2200itag 2200-watt 1...   \n",
       "1824  {'product_name': 'wanapure 25pcs copper metal ...   \n",
       "1825  {'product_name': 'j r peters 52024 jacks class...   \n",
       "1826  {'product_name': 'jack's classic 10-30-20 blos...   \n",
       "1827  {'product_name': 'antonki room thermometer ind...   \n",
       "\n",
       "                           negative_recommended_product  \\\n",
       "0     [{'product_name': 'Keter City 30 Gallon Resin ...   \n",
       "1                                                    []   \n",
       "2     [{'product_name': 'YARDEC Gopher Repellent Ult...   \n",
       "3     [{'product_name': 'Westinghouse Outdoor Power ...   \n",
       "4     [{'product_name': 'Premium Water Soluble Ferti...   \n",
       "...                                                 ...   \n",
       "1823  [{'product_name': 'Honda 664240 EU2200i 2200 W...   \n",
       "1824  [{'product_name': 'Vktech 5000pcs 6 x10cm Plas...   \n",
       "1825  [{'product_name': 'J R Peters Jacks Classic No...   \n",
       "1826  [{'product_name': 'Neptune's Harvest Tomato & ...   \n",
       "1827  [{'product_name': 'La Crosse Technology TX141T...   \n",
       "\n",
       "                                                  turns  \n",
       "0     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "2     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "3     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "4     [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "...                                                 ...  \n",
       "1823  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1824  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1825  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1826  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "1827  [{'turn': 1, 'is_rec': False, 'user_accept_rec...  \n",
       "\n",
       "[1828 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"google/flan-t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8533 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8533/8533 [01:44<00:00, 81.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 146\n",
      "len(prompt_train): 8387\n",
      "len(recommend_train): 8387\n"
     ]
    }
   ],
   "source": [
    "prompt_train = []\n",
    "recommend_train = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_train.iterrows(), total=len(df_recommender_train)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_train.append(prompt)\n",
    "                recommend_train.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_train): {len(prompt_train)}\")\n",
    "print(f\"len(recommend_train): {len(recommend_train)}\")\n",
    "\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_train, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_train, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_train = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1828 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1828/1828 [00:23<00:00, 77.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 57\n",
      "len(prompt_validation): 1771\n",
      "len(recommend_validation): 1771\n"
     ]
    }
   ],
   "source": [
    "prompt_validation = []\n",
    "recommend_validation = []\n",
    "not_founds = 0\n",
    "\n",
    "for _, row in tqdm(df_recommender_validation.iterrows(), total=len(df_recommender_validation)):\n",
    "    prompt = \"\"\n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if \"COMPUTER\" in turn:\n",
    "            computer = turn[\"COMPUTER\"]\n",
    "            \n",
    "            if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "                prompt += \"computer: I would recommend the \"\n",
    "                prompt_validation.append(prompt)\n",
    "                recommend_validation.append(recommended)\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "        \n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"len(prompt_validation): {len(prompt_validation)}\")\n",
    "print(f\"len(recommend_validation): {len(recommend_validation)}\")\n",
    "            \n",
    "            \n",
    "prompt_encodings = tokenizer(prompt_validation, padding='max_length', max_length=1024, truncation=True, return_tensors='pt')\n",
    "recommend_encodings = tokenizer(recommend_validation, padding='max_length', max_length=32, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = recommend_encodings['input_ids']\n",
    "labels[labels == tokenizer.pad_token_id] = IGNORE_INDEX\n",
    "\n",
    "dataset = {\n",
    "    'input_ids': prompt_encodings['input_ids'],\n",
    "    'attention_mask': prompt_encodings['attention_mask'],\n",
    "    'labels': labels,\n",
    "}\n",
    "dataset_validation = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    input_ids, attention_mask, labels,  = [], [], []\n",
    "    for sample in batch:\n",
    "        input_ids.append(sample['input_ids'])\n",
    "        attention_mask.append(sample['attention_mask'])\n",
    "        labels.append(sample['labels'])\n",
    "    max_encoder_len = max(sum(x) for x in attention_mask)\n",
    "    max_decoder_len = max(sum([0 if item == IGNORE_INDEX else 1 for item in x]) for x in labels)\n",
    "    return {\n",
    "        'input_ids': torch.tensor(input_ids)[:, :max_encoder_len],\n",
    "        'attention_mask': torch.tensor(attention_mask)[:, :max_encoder_len],\n",
    "        'labels': torch.tensor(labels)[:, :max_decoder_len]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_garden/T5_recommender\",\n",
    "    num_train_epochs=5,\n",
    "    # logging_steps=500,\n",
    "    # logging_dir=self.cfg.logging_dir,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=0.3,#self.cfg.save_steps,\n",
    "    eval_steps=0.3, #self.cfg.eval_steps,\n",
    "    save_total_limit=3,\n",
    "    gradient_accumulation_steps=3, #gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=4, #train_batch_size,\n",
    "    per_device_eval_batch_size=4, #self.cfg.eval_batch_size,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    # dataloader_drop_last=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_validation,\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3495/3495 32:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1049</td>\n",
       "      <td>3.245900</td>\n",
       "      <td>2.983224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>2.948500</td>\n",
       "      <td>2.895374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3147</td>\n",
       "      <td>2.812100</td>\n",
       "      <td>2.845237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # resume_from_checkpoint=True\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_garden/splits/test.jsonl\"\n",
    "df_recommender_test = pd.read_json(input_file, lines=True)\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    row[\"recommended_product\"][\"product_name\"] = row[\"recommended_product\"][\"product_name\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_training_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/dataset/amazon_garden/garden_df.csv\"\n",
    "\n",
    "all_apps = []\n",
    "with open(apps_training_path, 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        all_apps.append(get_first_five_words(row[\"title\"].lower()))\n",
    "        \n",
    "all_apps = list(set(all_apps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_creator(row):\n",
    "    np.random.seed(row.name)\n",
    "    selected_values = np.random.choice(np.setdiff1d( all_apps, [get_first_five_words(row[\"recommended_product\"][\"product_name\"])]), 24, replace=False) # filter_candidate_apps(row[\"recommended_book\"][\"book_name\"])\n",
    "    random_position = np.random.randint(0, len(selected_values) + 1)\n",
    "    \n",
    "    return np.insert(selected_values, random_position, get_first_five_words(row[\"recommended_product\"][\"product_name\"])) \n",
    "\n",
    "df_recommender_test['candidate'] = df_recommender_test.apply(lambda row: candidate_creator(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find 70\n",
      "Number of prompt: 1759\n",
      "Number of generations: 1759\n",
      "Number of candidate apps: 1759\n",
      "Number of true candidate indexes: 1759\n"
     ]
    }
   ],
   "source": [
    "prompt_test = []\n",
    "recommend_test = []\n",
    "candidate_books = []\n",
    "true_candidate_indexes = []\n",
    "not_founds = 0\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    candidates = []\n",
    "    for index, candidate_book in enumerate(row[\"candidate\"].tolist()):\n",
    "        candidates.append(candidate_book)\n",
    "        if candidate_book == get_first_five_words(row[\"recommended_product\"][\"product_name\"]):\n",
    "            true_candidate_index = index\n",
    "    prompt = \"\"\n",
    "    \n",
    "    found = False\n",
    "    recommended = get_first_five_words(row[\"recommended_product\"][\"product_name\"])\n",
    "    \n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        computer = turn[\"COMPUTER\"]\n",
    "        \n",
    "        if fuzz.partial_ratio(recommended, computer.lower()) >= 95:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            prompt_test.append(prompt)\n",
    "            recommend_test.append(recommended)\n",
    "            candidate_books.append(candidates)\n",
    "            true_candidate_indexes.append(true_candidate_index)\n",
    "            found = True\n",
    "            break\n",
    "        else:\n",
    "            prompt += \"computer: \"+ computer + \"\\n\"\n",
    "        \n",
    "        if \"HUMAN\" in turn:\n",
    "            human = turn[\"HUMAN\"]\n",
    "            prompt += \"human: \" + human + \"\\n\"\n",
    "    \n",
    "    if not found:\n",
    "        not_founds += 1\n",
    "\n",
    "print(f\"Could not find {not_founds}\")\n",
    "print(f\"Number of prompt: {len(prompt_test)}\")\n",
    "print(f\"Number of generations: {len(recommend_test)}\")\n",
    "print(f\"Number of candidate apps: {len(candidate_books)}\")\n",
    "print(f\"Number of true candidate indexes: {len(true_candidate_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/u-spa-d4/grad/mfe261/Projects/MobileConvRec/envs/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path = \"/u/spa-d4/grad/mfe261/Projects/MobileConvRec/models/new_models/amazon_garden/T5_recommender\")\n",
    "model.eval()\n",
    "model = model.to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", additional_special_tokens=[\"computer:\", \"human:\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70):\n",
    "  prompt_batches = list(chunk(prompt_test, batch_size))\n",
    "  generation_batches = list(chunk(recommend_test, batch_size))\n",
    "\n",
    "  correctly_predicted = []\n",
    "  for prompt_batch, generation_batch in tqdm(zip(prompt_batches, generation_batches), total = len(generation_batches)):\n",
    "\n",
    "    inputs = tokenizer(prompt_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\n",
    "    generations_predicted = model.generate(input_ids=inputs[\"input_ids\"].to('cuda'), attention_mask=inputs[\"attention_mask\"].to('cuda'),\n",
    "                            max_new_tokens=32,\n",
    "                            num_beams=8,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id) # length_penalty=0.8, Set length_penalty to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "\n",
    "    decoded_generations = [tokenizer.decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generation in generations_predicted]\n",
    "    generation_batch = [generation for generation in generation_batch]\n",
    "    \n",
    "    correctly_predicted.extend([1 if fuzz.ratio(predicted, ground_truth) > threshold else 0 for predicted, ground_truth in zip(decoded_generations, generation_batch)])\n",
    "\n",
    "  return correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [04:30<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.07276861853325753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(prompt_test, recommend_test, model, tokenizer, batch_size=8, threshold=70)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "    \n",
    "def convert_to_sublists(numbers, sublist_size):\n",
    "    return [numbers[i:i+sublist_size] for i in range(0, len(numbers), sublist_size)]\n",
    "\n",
    "def recommender_rank(prompts, candidate_apps, model, tokenizer, batch_size=8):\n",
    "  model.eval()\n",
    "  encoder_max_length = 1024\n",
    "  decoder_max_length = 32\n",
    "  prompts_tokenized = tokenizer(prompts, max_length=encoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "  \n",
    "  input_ids_decoder = []\n",
    "  attention_mask_decoder = []\n",
    "  input_ids_encoder = []\n",
    "  attention_mask_encoder  = []\n",
    "  for index, candidate_app_elements in enumerate(candidate_apps):\n",
    "    candidate_app_elements = [tokenizer.pad_token+element for element in candidate_app_elements] # adding pad token to the beginning of each candidate app\n",
    "    candidate_apps_tokenized = tokenizer(candidate_app_elements, max_length=decoder_max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    for candidate_app_index in range(len(candidate_app_elements)):\n",
    "      input_ids_decoder.append(candidate_apps_tokenized[\"input_ids\"][candidate_app_index])\n",
    "      attention_mask_decoder.append(candidate_apps_tokenized[\"attention_mask\"][candidate_app_index])\n",
    "      input_ids_encoder.append(prompts_tokenized[\"input_ids\"][index])\n",
    "      attention_mask_encoder.append(prompts_tokenized[\"attention_mask\"][index])\n",
    "  \n",
    "  input_ids_encoder_batches = list(chunk(input_ids_encoder, batch_size))\n",
    "  attention_mask_encoder_batches = list(chunk(attention_mask_encoder, batch_size))\n",
    "  input_ids_decoder_batches = list(chunk(input_ids_decoder, batch_size))\n",
    "  attention_mask_decoder_batches = list(chunk(attention_mask_decoder, batch_size))\n",
    "  \n",
    "\n",
    "  scores = []\n",
    "  for input_ids_encoder_batch, attention_mask_encoder_batch, input_ids_decoder_batch, attention_mask_decoder_batch in tqdm(zip(input_ids_encoder_batches, attention_mask_encoder_batches, input_ids_decoder_batches, attention_mask_decoder_batches), total = len(input_ids_encoder_batches)):\n",
    "    decoder_input_ids = torch.stack(input_ids_decoder_batch).to(\"cuda\")\n",
    "    decoder_attention_mask = torch.stack(attention_mask_decoder_batch).to(\"cuda\")\n",
    "    input_ids = torch.stack(input_ids_encoder_batch).to(\"cuda\")\n",
    "    attention_mask = torch.stack(attention_mask_encoder_batch).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "      model_output = model(decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask, \n",
    "                           input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logprobs = F.log_softmax(model_output[\"logits\"], dim=-1)[:, :-1, :] # remove the eos token\n",
    "    output_tokens = decoder_input_ids[:, 1:] # remove the bos token\n",
    "        \n",
    "    tokens_logprobs = torch.gather(logprobs, 2, output_tokens[:, :, None]).squeeze(-1).to(torch.float32)\n",
    "        \n",
    "    mask = torch.ones(tokens_logprobs.shape, dtype=torch.bool, device=\"cuda\")\n",
    "    for i, _output in enumerate(output_tokens):\n",
    "      for j, _token in enumerate(_output):\n",
    "        if _token == tokenizer.pad_token_id:\n",
    "          mask[i, j] = False\n",
    "              \n",
    "    score = (tokens_logprobs * mask).sum(-1) / mask.sum(-1)\n",
    "    scores.extend(score.to('cpu').tolist())\n",
    "    \n",
    "  # batch_input_representations = torch.cat(batch_input_representations)\n",
    "  \n",
    "  scores = convert_to_sublists(scores, len(candidate_apps[0]))\n",
    "  \n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5497/5497 [20:40<00:00,  4.43it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = recommender_rank(prompt_test, candidate_books, model, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampled Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.7009664582148948),\n",
       " np.float64(0.8032973280272883),\n",
       " np.float64(0.8573052870949404),\n",
       " np.float64(0.8908470722001137),\n",
       " np.float64(0.9198408186469585),\n",
       " np.float64(0.939169982944855),\n",
       " np.float64(0.9511085844229676),\n",
       " np.float64(0.9596361569073337),\n",
       " np.float64(0.9670267197271177),\n",
       " np.float64(0.9749857873791927)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is the one\n",
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.7009664582148948),\n",
       " np.float64(0.7655300486883811),\n",
       " np.float64(0.7925340282222072),\n",
       " np.float64(0.8069796887829405),\n",
       " np.float64(0.8181960009881489),\n",
       " np.float64(0.8250811882318516),\n",
       " np.float64(0.829060722057889),\n",
       " np.float64(0.831750871660951),\n",
       " np.float64(0.8339756527545449),\n",
       " np.float64(0.8362763392630443)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is the one\n",
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[top_k_accuracy_score(true_candidate_indexes, scores, k=k) for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_relevance = [[1 if item == index else 0 for item in range(len(candidate_books[0]))] for index in true_candidate_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ndcg_score(true_relevance, scores, k=k) for k in range(1, 11)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
