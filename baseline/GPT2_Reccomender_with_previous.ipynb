{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/amo-d1/grad/sma340/envs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/u/amo-d1/grad/sma340/envs/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "from fuzzywuzzy import fuzz\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_approximate_substring(substring, string, threshold=70):\n",
    "    for i in range(len(string) - len(substring) + 1):\n",
    "        window = string[i:i+len(substring)]\n",
    "        similarity_ratio = fuzz.ratio(substring, window)\n",
    "        if similarity_ratio >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8720 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8720/8720 [00:21<00:00, 405.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8720\n",
      "8720\n",
      "8720\n",
      "8720\n",
      "\n",
      "number of rows: 8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_training_path = \"/u/amo-d1/grad/sma340/project/llmrank/MobileConvRec-Main/dialogs/training\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_training_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_training_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_train = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_train = df_recommender_train[(df_recommender_train[\"recommend_indexes\"] != -1) & (df_recommender_train[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 68/1285 [00:00<00:01, 673.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:03<00:00, 358.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n",
      "1285\n",
      "1285\n",
      "1285\n",
      "\n",
      "number of rows: 1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_validation_path = \"/u/amo-d1/grad/sma340/project/llmrank/MobileConvRec-Main/dialogs/validation\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_validation_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_validation_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_validation = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_validation = df_recommender_validation[(df_recommender_validation[\"recommend_indexes\"] != -1) & (df_recommender_validation[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for turn in df_recommender_train['turns']:\n",
    "    if len(turn) == 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for recommend_index in df_recommender_train['recommend_indexes']:\n",
    "    if recommend_index == -1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for turn in df_recommender_validation['turns']:\n",
    "    if len(turn) == 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for recommend_index in df_recommender_validation['recommend_indexes']:\n",
    "    if recommend_index == -1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>previous_interactions</th>\n",
       "      <th>recommended_app_name</th>\n",
       "      <th>turns</th>\n",
       "      <th>recommend_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vtg1e7gwd7akgogt</td>\n",
       "      <td>drag battle, twitch: live game streaming, mam...</td>\n",
       "      <td>uno!ãâ¯ãâ¿ãâ½</td>\n",
       "      <td>[computer: hello! what brings you here today?,...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kp38ptk4vwffenzn</td>\n",
       "      <td>blockstarplanet, lotsa slots - casino games</td>\n",
       "      <td>snapchat</td>\n",
       "      <td>[computer: hi there! what are you looking for ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4704gqsclz6315op</td>\n",
       "      <td>golf clash, xender - share music transfer, nf...</td>\n",
       "      <td>video downloader</td>\n",
       "      <td>[computer: hi there! how can i assist you toda...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnvsafiijygjzyvk</td>\n",
       "      <td>csr classics, tata cliq shopping app india, f...</td>\n",
       "      <td>piano fire: edm music &amp; piano</td>\n",
       "      <td>[computer: hello! how can i help you today?, h...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tmxwkzm2cat22pvh</td>\n",
       "      <td>the house of da vinci, pet rescue saga, facem...</td>\n",
       "      <td>facebook</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>rsbsgtmy4ncjvhdx</td>\n",
       "      <td>waze - gps, maps, traffic alerts &amp; live navig...</td>\n",
       "      <td>bitmoji</td>\n",
       "      <td>[computer: hey there! what are you looking for...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>nzhuiko02pyj8vro</td>\n",
       "      <td>video editor app - vivacut</td>\n",
       "      <td>music player - mp3 player</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>ldzrids0o452udvr</td>\n",
       "      <td>the frostrune, ark: survival evolved, street ...</td>\n",
       "      <td>colornote notepad notes</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>lekzvahdmv1bcian</td>\n",
       "      <td>pandora - music &amp; podcasts, kingdom rush veng...</td>\n",
       "      <td>minecraft</td>\n",
       "      <td>[computer: hi! how can i help you today?, huma...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>4hced3vnrxtganiq</td>\n",
       "      <td>hide online - hunters vs props, onmyoji arena...</td>\n",
       "      <td>self - build credit &amp; savings</td>\n",
       "      <td>[computer: sure! what kind of credit building ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                              previous_interactions  \\\n",
       "0     vtg1e7gwd7akgogt   drag battle, twitch: live game streaming, mam...   \n",
       "1     kp38ptk4vwffenzn        blockstarplanet, lotsa slots - casino games   \n",
       "2     4704gqsclz6315op   golf clash, xender - share music transfer, nf...   \n",
       "3     rnvsafiijygjzyvk   csr classics, tata cliq shopping app india, f...   \n",
       "4     tmxwkzm2cat22pvh   the house of da vinci, pet rescue saga, facem...   \n",
       "...                ...                                                ...   \n",
       "1280  rsbsgtmy4ncjvhdx   waze - gps, maps, traffic alerts & live navig...   \n",
       "1281  nzhuiko02pyj8vro                         video editor app - vivacut   \n",
       "1282  ldzrids0o452udvr   the frostrune, ark: survival evolved, street ...   \n",
       "1283  lekzvahdmv1bcian   pandora - music & podcasts, kingdom rush veng...   \n",
       "1284  4hced3vnrxtganiq   hide online - hunters vs props, onmyoji arena...   \n",
       "\n",
       "               recommended_app_name  \\\n",
       "0                  uno!ãâ¯ãâ¿ãâ½   \n",
       "1                          snapchat   \n",
       "2                  video downloader   \n",
       "3     piano fire: edm music & piano   \n",
       "4                          facebook   \n",
       "...                             ...   \n",
       "1280                        bitmoji   \n",
       "1281      music player - mp3 player   \n",
       "1282        colornote notepad notes   \n",
       "1283                      minecraft   \n",
       "1284  self - build credit & savings   \n",
       "\n",
       "                                                  turns  recommend_indexes  \n",
       "0     [computer: hello! what brings you here today?,...                 22  \n",
       "1     [computer: hi there! what are you looking for ...                 20  \n",
       "2     [computer: hi there! how can i assist you toda...                  2  \n",
       "3     [computer: hello! how can i help you today?, h...                 22  \n",
       "4     [computer: hi there! how can i help you today?...                 22  \n",
       "...                                                 ...                ...  \n",
       "1280  [computer: hey there! what are you looking for...                 12  \n",
       "1281  [computer: hi there! how can i help you today?...                 24  \n",
       "1282  [computer: hi there! how can i help you today?...                 20  \n",
       "1283  [computer: hi! how can i help you today?, huma...                 20  \n",
       "1284  [computer: sure! what kind of credit building ...                 20  \n",
       "\n",
       "[1267 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>previous_interactions</th>\n",
       "      <th>recommended_app_name</th>\n",
       "      <th>turns</th>\n",
       "      <th>recommend_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mw3eetfcrkivh692</td>\n",
       "      <td>calm - meditate, sleep, relax, kahoot! play &amp;...</td>\n",
       "      <td>fishdom</td>\n",
       "      <td>[computer: hi! how can i help you today?, huma...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ttbcevntpi81xyq</td>\n",
       "      <td>None</td>\n",
       "      <td>pokãâ¯ãâ¿ãâ½mon quest</td>\n",
       "      <td>[computer: hi! need help finding a pokãâãâ©...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xj3hkxd3ms7sbgrk</td>\n",
       "      <td>cat escape, math kids: math games for kids, r...</td>\n",
       "      <td>sonic dash - endless running</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdfiesy5vzbpkz58</td>\n",
       "      <td>animal jam, brave private web browser, starz,...</td>\n",
       "      <td>pixel gun 3d - battle royale</td>\n",
       "      <td>[computer: hello there! how can i assist you t...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1putumtxe7yw3vl</td>\n",
       "      <td>war heroes: strategy card game, meetme: chat ...</td>\n",
       "      <td>stick war: legacy</td>\n",
       "      <td>[computer: hello! how can i help you today?, h...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>dxkdnbbfqx25oqa9</td>\n",
       "      <td>google go: a lighter, faster way to search, a...</td>\n",
       "      <td>whatsapp messenger</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>r0ad7rnsodtnrkea</td>\n",
       "      <td>speedtest by ookla, kitten match, gamee prize...</td>\n",
       "      <td>pk xd - play with your friends</td>\n",
       "      <td>[computer: hello there! how can i help you tod...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>1c30afayr0kyblrc</td>\n",
       "      <td>stickman party: 1 2 3 4 player games free, li...</td>\n",
       "      <td>ludo club - fun dice game</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>mkh0usitaxezqehu</td>\n",
       "      <td>warhammer 40,000: lost crusade, hot wheels un...</td>\n",
       "      <td>garena free fire max</td>\n",
       "      <td>[computer: hi there! how can i assist you toda...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>yj1yj9bl3h3vvtjb</td>\n",
       "      <td>credit karma, mytherapy pill reminder, beauty...</td>\n",
       "      <td>soundcloud: play music &amp; songs</td>\n",
       "      <td>[computer: hello! how can i help you today?, h...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                              previous_interactions  \\\n",
       "0     mw3eetfcrkivh692   calm - meditate, sleep, relax, kahoot! play &...   \n",
       "1     7ttbcevntpi81xyq                                               None   \n",
       "2     xj3hkxd3ms7sbgrk   cat escape, math kids: math games for kids, r...   \n",
       "3     pdfiesy5vzbpkz58   animal jam, brave private web browser, starz,...   \n",
       "4     p1putumtxe7yw3vl   war heroes: strategy card game, meetme: chat ...   \n",
       "...                ...                                                ...   \n",
       "8715  dxkdnbbfqx25oqa9   google go: a lighter, faster way to search, a...   \n",
       "8716  r0ad7rnsodtnrkea   speedtest by ookla, kitten match, gamee prize...   \n",
       "8717  1c30afayr0kyblrc   stickman party: 1 2 3 4 player games free, li...   \n",
       "8718  mkh0usitaxezqehu   warhammer 40,000: lost crusade, hot wheels un...   \n",
       "8719  yj1yj9bl3h3vvtjb   credit karma, mytherapy pill reminder, beauty...   \n",
       "\n",
       "                recommended_app_name  \\\n",
       "0                            fishdom   \n",
       "1           pokãâ¯ãâ¿ãâ½mon quest   \n",
       "2       sonic dash - endless running   \n",
       "3       pixel gun 3d - battle royale   \n",
       "4                  stick war: legacy   \n",
       "...                              ...   \n",
       "8715              whatsapp messenger   \n",
       "8716  pk xd - play with your friends   \n",
       "8717       ludo club - fun dice game   \n",
       "8718            garena free fire max   \n",
       "8719  soundcloud: play music & songs   \n",
       "\n",
       "                                                  turns  recommend_indexes  \n",
       "0     [computer: hi! how can i help you today?, huma...                 20  \n",
       "1     [computer: hi! need help finding a pokãâãâ©...                 14  \n",
       "2     [computer: hi there! how can i help you today?...                 24  \n",
       "3     [computer: hello there! how can i assist you t...                 20  \n",
       "4     [computer: hello! how can i help you today?, h...                 20  \n",
       "...                                                 ...                ...  \n",
       "8715  [computer: hi there! how can i help you today?...                 18  \n",
       "8716  [computer: hello there! how can i help you tod...                 20  \n",
       "8717  [computer: hi there! how can i help you today?...                 18  \n",
       "8718  [computer: hi there! how can i assist you toda...                 18  \n",
       "8719  [computer: hello! how can i help you today?, h...                 18  \n",
       "\n",
       "[8644 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"gpt2\"\n",
    "bos = '<|startoftext|>'\n",
    "eos = '<|endoftext|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, bos_token=bos, eos_token=eos, pad_token=pad, additional_special_tokens=[\"computer:\", \"human:\", \"previous_interactions:\"])\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model_max_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.truncation_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RecommenderItem:\n",
    "    prompt: str\n",
    "    generation: Optional[str] = None\n",
    "    \n",
    "class recommenderDataset(Dataset):\n",
    "    def __init__(self, data: List[RecommenderItem]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> RecommenderItem:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_validation = []\n",
    "for _, row in df_recommender_validation.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_validation.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\" + eos))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_train = []\n",
    "for _, row in df_recommender_train.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_train.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\" + eos))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|startoftext|>previous_interactions: calm - meditate, sleep, relax, kahoot! play & create quizzes\\ncomputer: hi! how can i help you today?\\nhuman: i'm looking for puzzle game apps for android devices.\\ncomputer: what type of puzzle games do you like?\\nhuman: i want apps with interactive gameplay.\\ncomputer: are you looking for apps with a rating of at least 4.3 stars?\\nhuman: yes, that's what i prefer.\\ncomputer: do you want a free or paid app?\\nhuman: free apps, please.\\ncomputer: do you want apps with a minimum of 10m user reviews?\\nhuman: yes, i prefer popular apps.\\ncomputer: do you have a preference for the content rating?\\nhuman: everyone is fine for me.\\ncomputer: i recommend trying the where's my water? 2 app based on your interests.\\nhuman: how are the ads in that app?\\ncomputer: some users have mentioned there are too many ads at times.\\nhuman: i think i'll try a different app.\\ncomputer: how about trying the toy blast app?\\nhuman: can you tell me more about toy blast?\\ncomputer: it has challenging and fun levels, but some users have mentioned limited lives as a concern.\\nhuman: i'll pass on that one. anything else you suggest?\\ncomputer: I would recommend the \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fishdom app.<|endoftext|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train[0].generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_collator(batch: list[recommenderDataset]): # for training a language model\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    for item in batch:\n",
    "        prompt_tokens = tokenizer.encode(item.prompt, return_tensors=\"pt\")[0] \n",
    "        generation_tokens = tokenizer.encode(item.generation, return_tensors=\"pt\")[0]\n",
    "        prompt_len = len(prompt_tokens)\n",
    "        generation_len = len(generation_tokens)\n",
    "        unused_len = model_max_length - prompt_len - generation_len\n",
    "        # handling case when input is greater than tokenizer length.\n",
    "        if unused_len < 0:\n",
    "            prompt_start_tokens = prompt_tokens[:1]\n",
    "            trimmed_prompt = prompt_tokens[unused_len * -1 + 1 :] # TODO: you could delete the prompt to reach the first |beginuser| token\n",
    "            prompt_tokens = torch.cat(\n",
    "                [prompt_start_tokens, trimmed_prompt], axis=0\n",
    "            )\n",
    "            prompt_len = len(prompt_tokens)\n",
    "            unused_len = 0\n",
    "        pad = torch.full([unused_len], tokenizer.pad_token_id)\n",
    "        input_tokens = torch.cat(\n",
    "            [prompt_tokens, generation_tokens, pad]\n",
    "        )\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.full(\n",
    "                    [prompt_len],\n",
    "                    -100,\n",
    "                ),\n",
    "                generation_tokens,\n",
    "                torch.full([unused_len], -100),\n",
    "            ]\n",
    "        )\n",
    "        attention_mask = torch.cat(\n",
    "            [\n",
    "                torch.full([prompt_len + generation_len], 1),\n",
    "                torch.full([unused_len], 0),\n",
    "            ]\n",
    "        )\n",
    "        input_ids.append(input_tokens)\n",
    "        attention_masks.append(attention_mask)\n",
    "        labels.append(label)\n",
    "\n",
    "    out = {\n",
    "        \"input_ids\": torch.stack(input_ids),\n",
    "        \"attention_mask\": torch.stack(attention_masks),\n",
    "        \"labels\": torch.stack(labels),\n",
    "    }\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/u/amo-d1/grad/sma340/project/llmrank/MobileConvRec-Main/metrics/outputs_with_interactions\",\n",
    "    num_train_epochs=5,\n",
    "    # logging_steps=500,\n",
    "    # logging_dir=self.cfg.logging_dir,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=1000,#self.cfg.save_steps,\n",
    "    eval_steps=1000, #self.cfg.eval_steps,\n",
    "    save_total_limit=3,\n",
    "    # gradient_accumulation_steps=10, #gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=4, #train_batch_size,\n",
    "    per_device_eval_batch_size=4, #self.cfg.eval_batch_size,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    # dataloader_drop_last=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=recommenderDataset(items_train),\n",
    "        eval_dataset=recommenderDataset(items_validation), #dm.datasets[DataNames.dev_language_model.value],\n",
    "        data_collator=training_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10805' max='10805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10805/10805 1:13:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.488800</td>\n",
       "      <td>1.290883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.806410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.688183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.597618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.550565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.509646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.508198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.483516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.482615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.482619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_approximate_substring(substring, string, threshold=70):\n",
    "    for i in range(len(string) - len(substring) + 1):\n",
    "        window = string[i:i+len(substring)]\n",
    "        similarity_ratio = fuzz.ratio(substring, window)\n",
    "        if similarity_ratio >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2557 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2557/2557 [00:06<00:00, 415.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2557\n",
      "2557\n",
      "2557\n",
      "2557\n",
      "\n",
      "number of rows: 2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_test_path = \"/u/amo-d1/grad/sma340/project/llmrank/MobileConvRec-Main/dialogs/testing\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_test_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_test_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_test = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_test = df_recommender_test[(df_recommender_test[\"recommend_indexes\"] != -1) & (df_recommender_test[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RecommenderItem:\n",
    "    prompt: str\n",
    "    generation: Optional[str] = None\n",
    "    \n",
    "class recommenderDataset(Dataset):\n",
    "    def __init__(self, data: List[RecommenderItem]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> RecommenderItem:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50262, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bos = '<|startoftext|>'\n",
    "eos = '<|endoftext|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", bos_token=bos, eos_token=eos, pad_token=pad, additional_special_tokens=[\"computer:\", \"human:\", \"previous_interactions:\"], padding_side='left')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/u/amo-d1/grad/sma340/project/llmrank/MobileConvRec-Main/metrics/outputs_with_interactions\").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_test = []\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_test.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\"))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def evaluate_recommender(dataset, model, tokenizer, batch_size=8, device=device, threshold=70):\n",
    "  prompt_arr = [data.prompt for data in dataset]\n",
    "  generation_arr = [data.generation for data in dataset]\n",
    "  prompt_batches = list(chunk(prompt_arr, batch_size))\n",
    "  generation_batches = list(chunk(generation_arr, batch_size))\n",
    "  max_length=992\n",
    "  generation_length = 32\n",
    "  correctly_predicted = []\n",
    "  for prompt_batch, generation_batch in tqdm(zip(prompt_batches, generation_batches), total = len(generation_batches)):\n",
    "\n",
    "    inputs = tokenizer(prompt_batch, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\n",
    "    generations_predicted = model.generate(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                            max_new_tokens=generation_length,\n",
    "                            num_beams=8,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id) # length_penalty=0.8, Set length_penalty to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "\n",
    "    generations_predicted = generations_predicted[:, max_length:] # we only need the generation part, not the prompt part.\n",
    "    decoded_generations = [tokenizer.decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True).replace(\" app.\", \"\")  for generation in generations_predicted]\n",
    "    generation_batch = [generation.replace(\" app.\", \"\") for generation in generation_batch]\n",
    "    \n",
    "    correctly_predicted.extend([1 if fuzz.ratio(predicted, ground_truth) > threshold else 0 for predicted, ground_truth in zip(decoded_generations, generation_batch)])\n",
    "\n",
    "\n",
    "  return correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_predicted = evaluate_recommender(recommenderDataset(items_test), model, tokenizer, batch_size=4, device=device)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 634/634 [13:00<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.597397476340694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(recommenderDataset(items_test), model, tokenizer, batch_size=4, device=device)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
