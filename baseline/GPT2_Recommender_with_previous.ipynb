{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "from fuzzywuzzy import fuzz\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_approximate_substring(substring, string, threshold=70):\n",
    "    for i in range(len(string) - len(substring) + 1):\n",
    "        window = string[i:i+len(substring)]\n",
    "        similarity_ratio = fuzz.ratio(substring, window)\n",
    "        if similarity_ratio >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/8720 [00:00<00:34, 249.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8720/8720 [00:25<00:00, 347.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8720\n",
      "8720\n",
      "8720\n",
      "8720\n",
      "\n",
      "number of rows: 8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_training_path = \"data/dataset_v2/training\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_training_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_training_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_train = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_train = df_recommender_train[(df_recommender_train[\"recommend_indexes\"] != -1) & (df_recommender_train[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [00:04<00:00, 302.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n",
      "1285\n",
      "1285\n",
      "1285\n",
      "\n",
      "number of rows: 1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_validation_path = \"data/dataset_v2/validation\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_validation_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_validation_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_validation = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_validation = df_recommender_validation[(df_recommender_validation[\"recommend_indexes\"] != -1) & (df_recommender_validation[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for turn in df_recommender_train['turns']:\n",
    "    if len(turn) == 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for recommend_index in df_recommender_train['recommend_indexes']:\n",
    "    if recommend_index == -1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for turn in df_recommender_validation['turns']:\n",
    "    if len(turn) == 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for recommend_index in df_recommender_validation['recommend_indexes']:\n",
    "    if recommend_index == -1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>previous_interactions</th>\n",
       "      <th>recommended_app_name</th>\n",
       "      <th>turns</th>\n",
       "      <th>recommend_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwttxhjcryqhatgb</td>\n",
       "      <td>None</td>\n",
       "      <td>wattpad - read &amp; write stories</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tugk24mlf1qvjzba</td>\n",
       "      <td>flight sim 2018</td>\n",
       "      <td>paytm -upi, money transfer, recharge, bill pay...</td>\n",
       "      <td>[computer: hi there! what brings you here toda...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hjbzfrhcuq2pxoma</td>\n",
       "      <td>dealdash - bid &amp; save auctions, heart's medic...</td>\n",
       "      <td>wood block puzzle - block game</td>\n",
       "      <td>[computer: hey there! how can i help you today...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0zm4n7djyrppfrgx</td>\n",
       "      <td>dangerous fellows: otome game, painnt - pro a...</td>\n",
       "      <td>dynamons 2</td>\n",
       "      <td>[computer: hey there! what are you looking for...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c7ofjyraazmwgr3</td>\n",
       "      <td>bumble - dating. friends. bizz, music player ...</td>\n",
       "      <td>2 player games : the challenge</td>\n",
       "      <td>[computer: hello! how can i help you today?, h...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>chyzv6ycokrxisoo</td>\n",
       "      <td>vector, command &amp; conquer: rivalsãâ¢ãâãâ¢...</td>\n",
       "      <td>my talking hank</td>\n",
       "      <td>[computer: hello! how can i help you today?, h...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>pfin90inkk8rauwn</td>\n",
       "      <td>wattpad beta, soccer star 22 top leagues, rai...</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>rog58g9ofnggpobe</td>\n",
       "      <td>journey: diary, journal, my ooredoo myanmar, ...</td>\n",
       "      <td>legoãâ¯ãâ¿ãâ½ friends: heartlake rush</td>\n",
       "      <td>[computer: hey there! what can i help you find...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>5s1a0sasi88h3mcq</td>\n",
       "      <td>age of war 2, noblemen: 1896, groupon ãâ¢ãâ...</td>\n",
       "      <td>human anatomy atlas 2021: complete 3d human body</td>\n",
       "      <td>[computer: hi there! what are you looking for ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>mlzi40v2kprwwi8x</td>\n",
       "      <td>chrome canary (unstable), colornote notepad n...</td>\n",
       "      <td>phoenix browser - fast &amp; safe</td>\n",
       "      <td>[computer: hey there! what brings you here tod...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                              previous_interactions  \\\n",
       "0     qwttxhjcryqhatgb                                               None   \n",
       "1     tugk24mlf1qvjzba                                    flight sim 2018   \n",
       "2     hjbzfrhcuq2pxoma   dealdash - bid & save auctions, heart's medic...   \n",
       "3     0zm4n7djyrppfrgx   dangerous fellows: otome game, painnt - pro a...   \n",
       "4     2c7ofjyraazmwgr3   bumble - dating. friends. bizz, music player ...   \n",
       "...                ...                                                ...   \n",
       "1280  chyzv6ycokrxisoo   vector, command & conquer: rivalsãâ¢ãâãâ¢...   \n",
       "1281  pfin90inkk8rauwn   wattpad beta, soccer star 22 top leagues, rai...   \n",
       "1282  rog58g9ofnggpobe   journey: diary, journal, my ooredoo myanmar, ...   \n",
       "1283  5s1a0sasi88h3mcq   age of war 2, noblemen: 1896, groupon ãâ¢ãâ...   \n",
       "1284  mlzi40v2kprwwi8x   chrome canary (unstable), colornote notepad n...   \n",
       "\n",
       "                                   recommended_app_name  \\\n",
       "0                        wattpad - read & write stories   \n",
       "1     paytm -upi, money transfer, recharge, bill pay...   \n",
       "2                        wood block puzzle - block game   \n",
       "3                                            dynamons 2   \n",
       "4                        2 player games : the challenge   \n",
       "...                                                 ...   \n",
       "1280                                    my talking hank   \n",
       "1281                                          pinterest   \n",
       "1282           legoãâ¯ãâ¿ãâ½ friends: heartlake rush   \n",
       "1283   human anatomy atlas 2021: complete 3d human body   \n",
       "1284                      phoenix browser - fast & safe   \n",
       "\n",
       "                                                  turns  recommend_indexes  \n",
       "0     [computer: hi there! how can i help you today?...                 18  \n",
       "1     [computer: hi there! what brings you here toda...                 24  \n",
       "2     [computer: hey there! how can i help you today...                 20  \n",
       "3     [computer: hey there! what are you looking for...                 24  \n",
       "4     [computer: hello! how can i help you today?, h...                 20  \n",
       "...                                                 ...                ...  \n",
       "1280  [computer: hello! how can i help you today?, h...                 22  \n",
       "1281  [computer: hi there! how can i help you today?...                 20  \n",
       "1282  [computer: hey there! what can i help you find...                 24  \n",
       "1283  [computer: hi there! what are you looking for ...                 12  \n",
       "1284  [computer: hey there! what brings you here tod...                 18  \n",
       "\n",
       "[1267 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>previous_interactions</th>\n",
       "      <th>recommended_app_name</th>\n",
       "      <th>turns</th>\n",
       "      <th>recommend_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1o00gcfxa7tj9fc</td>\n",
       "      <td>snipers vs thieves, retro bowl, be the king: ...</td>\n",
       "      <td>weather forecast - accurate local weather &amp; wi...</td>\n",
       "      <td>[computer: hello! how can i assist you today?,...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tjfy73vbqa5acgac</td>\n",
       "      <td>daily shopping stories, truck simulator 2018 ...</td>\n",
       "      <td>bridge race</td>\n",
       "      <td>[computer: hi there! what are you looking for ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okqwykkowhwv8ppo</td>\n",
       "      <td>shop titans: craft &amp; build, dragon ball z dok...</td>\n",
       "      <td>video editor &amp; maker videoshow</td>\n",
       "      <td>[computer: are you looking for apps that are e...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>och0j9udd8rwbezp</td>\n",
       "      <td>pepi wonder world: magic isle!, the simsãâ¯ã...</td>\n",
       "      <td>ludo star</td>\n",
       "      <td>[computer: hi! how can i help you today?, huma...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86ckfhrgr3my1asp</td>\n",
       "      <td>microsoft onenote: save ideas and organize no...</td>\n",
       "      <td>xender - share music transfer</td>\n",
       "      <td>[computer: hey there! what can i help you with...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>dkfqslrdxlhbegdr</td>\n",
       "      <td>None</td>\n",
       "      <td>true fear: forsaken souls 1</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>8lw0qo1crrzsoef9</td>\n",
       "      <td>macy's, play to win: win real money, opera ne...</td>\n",
       "      <td>hill climb racing 2</td>\n",
       "      <td>[computer: hey there! how can i help you today...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>xqbiugex5rwctlsp</td>\n",
       "      <td>jurassic world alive, google classroom</td>\n",
       "      <td>zombie catchers ãâ¯ãâ¿ãâ½ love to hunt</td>\n",
       "      <td>[computer: sure thing! what kinds of zombie hu...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>xpo2xk6chiiygdp3</td>\n",
       "      <td>playmobil luxury mansion, into the dead 2, sc...</td>\n",
       "      <td>township</td>\n",
       "      <td>[computer: hi there! how can i help you today?...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>xm36yeto9tlqbfsa</td>\n",
       "      <td>None</td>\n",
       "      <td>video maker</td>\n",
       "      <td>[computer: hi there! what brings you here toda...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                              previous_interactions  \\\n",
       "0     d1o00gcfxa7tj9fc   snipers vs thieves, retro bowl, be the king: ...   \n",
       "1     tjfy73vbqa5acgac   daily shopping stories, truck simulator 2018 ...   \n",
       "2     okqwykkowhwv8ppo   shop titans: craft & build, dragon ball z dok...   \n",
       "3     och0j9udd8rwbezp   pepi wonder world: magic isle!, the simsãâ¯ã...   \n",
       "4     86ckfhrgr3my1asp   microsoft onenote: save ideas and organize no...   \n",
       "...                ...                                                ...   \n",
       "8715  dkfqslrdxlhbegdr                                               None   \n",
       "8716  8lw0qo1crrzsoef9   macy's, play to win: win real money, opera ne...   \n",
       "8717  xqbiugex5rwctlsp             jurassic world alive, google classroom   \n",
       "8718  xpo2xk6chiiygdp3   playmobil luxury mansion, into the dead 2, sc...   \n",
       "8719  xm36yeto9tlqbfsa                                               None   \n",
       "\n",
       "                                   recommended_app_name  \\\n",
       "0     weather forecast - accurate local weather & wi...   \n",
       "1                                           bridge race   \n",
       "2                        video editor & maker videoshow   \n",
       "3                                             ludo star   \n",
       "4                         xender - share music transfer   \n",
       "...                                                 ...   \n",
       "8715                        true fear: forsaken souls 1   \n",
       "8716                                hill climb racing 2   \n",
       "8717          zombie catchers ãâ¯ãâ¿ãâ½ love to hunt   \n",
       "8718                                           township   \n",
       "8719                                        video maker   \n",
       "\n",
       "                                                  turns  recommend_indexes  \n",
       "0     [computer: hello! how can i assist you today?,...                 24  \n",
       "1     [computer: hi there! what are you looking for ...                 18  \n",
       "2     [computer: are you looking for apps that are e...                 16  \n",
       "3     [computer: hi! how can i help you today?, huma...                 24  \n",
       "4     [computer: hey there! what can i help you with...                 22  \n",
       "...                                                 ...                ...  \n",
       "8715  [computer: hi there! how can i help you today?...                 24  \n",
       "8716  [computer: hey there! how can i help you today...                 16  \n",
       "8717  [computer: sure thing! what kinds of zombie hu...                 22  \n",
       "8718  [computer: hi there! how can i help you today?...                 20  \n",
       "8719  [computer: hi there! what brings you here toda...                  2  \n",
       "\n",
       "[8644 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"gpt2\"\n",
    "bos = '<|startoftext|>'\n",
    "eos = '<|endoftext|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint, bos_token=bos, eos_token=eos, pad_token=pad, additional_special_tokens=[\"computer:\", \"human:\", \"previous_interactions:\"])\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint).to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model_max_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.truncation_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RecommenderItem:\n",
    "    prompt: str\n",
    "    generation: Optional[str] = None\n",
    "    \n",
    "class recommenderDataset(Dataset):\n",
    "    def __init__(self, data: List[RecommenderItem]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> RecommenderItem:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_validation = []\n",
    "for _, row in df_recommender_validation.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_validation.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\" + eos))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_train = []\n",
    "for _, row in df_recommender_train.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_train.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\" + eos))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|startoftext|>previous_interactions: snipers vs thieves, retro bowl, be the king: judge destiny, x-plane flight simulator, karaoke - sing songs, filemaster: file manage, file transfer power clean, calm - meditate, sleep, relax, dragon raja, funimate video editor & maker, facemoji emoji keyboard&fonts\\ncomputer: hello! how can i assist you today?\\nhuman: i want to find a weather forecast app for my android phone.\\ncomputer: what kind of weather forecast app are you looking for?\\nhuman: i want one that is accurate.\\ncomputer: do you prefer apps with a rating of everyone?\\nhuman: yes, i prefer everyone rated apps.\\ncomputer: are you looking for a free app or are you willing to pay?\\nhuman: i would prefer a free app.\\ncomputer: would you be okay with occasional ads in the app?\\nhuman: yes, i can consider apps with ads.\\ncomputer: do you prefer apps with high average ratings from users?\\nhuman: yes, i prefer apps with at least a 4.8 star rating.\\ncomputer: based on your preferences, i recommend checking out the weather channel - radar app.\\nhuman: how often does the app refresh?\\ncomputer: some users have mentioned there are too many ads in the app.\\nhuman: i would like to find an app with fewer ads. can you suggest another one?\\ncomputer: how about trying accuweather: weather radar app?\\nhuman: how does this app's radar feature work?\\ncomputer: some users have reported that the radar is slow.\\nhuman: i'd prefer to avoid slow radar. do you have any other suggestions?\\ncomputer: how about trying weather home - live radar app?\\nhuman: tell me more about weather home - live radar.\\ncomputer: many users have said that it takes over the user interface. are you interested in trying it?\\nhuman: i'm concerned about that. do you have any other suggestions?\\ncomputer: I would recommend the \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather forecast - accurate local weather & widget app.<|endoftext|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train[0].generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_collator(batch: list[recommenderDataset]): # for training a language model\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    for item in batch:\n",
    "        prompt_tokens = tokenizer.encode(item.prompt, return_tensors=\"pt\")[0] \n",
    "        generation_tokens = tokenizer.encode(item.generation, return_tensors=\"pt\")[0]\n",
    "        prompt_len = len(prompt_tokens)\n",
    "        generation_len = len(generation_tokens)\n",
    "        unused_len = model_max_length - prompt_len - generation_len\n",
    "        # handling case when input is greater than tokenizer length.\n",
    "        if unused_len < 0:\n",
    "            prompt_start_tokens = prompt_tokens[:1]\n",
    "            trimmed_prompt = prompt_tokens[unused_len * -1 + 1 :] # TODO: you could delete the prompt to reach the first |beginuser| token\n",
    "            prompt_tokens = torch.cat(\n",
    "                [prompt_start_tokens, trimmed_prompt], axis=0\n",
    "            )\n",
    "            prompt_len = len(prompt_tokens)\n",
    "            unused_len = 0\n",
    "        pad = torch.full([unused_len], tokenizer.pad_token_id)\n",
    "        input_tokens = torch.cat(\n",
    "            [prompt_tokens, generation_tokens, pad]\n",
    "        )\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.full(\n",
    "                    [prompt_len],\n",
    "                    -100,\n",
    "                ),\n",
    "                generation_tokens,\n",
    "                torch.full([unused_len], -100),\n",
    "            ]\n",
    "        )\n",
    "        attention_mask = torch.cat(\n",
    "            [\n",
    "                torch.full([prompt_len + generation_len], 1),\n",
    "                torch.full([unused_len], 0),\n",
    "            ]\n",
    "        )\n",
    "        input_ids.append(input_tokens)\n",
    "        attention_masks.append(attention_mask)\n",
    "        labels.append(label)\n",
    "\n",
    "    out = {\n",
    "        \"input_ids\": torch.stack(input_ids),\n",
    "        \"attention_mask\": torch.stack(attention_masks),\n",
    "        \"labels\": torch.stack(labels),\n",
    "    }\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/GPT2_previous_interactions\",\n",
    "    num_train_epochs=5,\n",
    "    # logging_steps=500,\n",
    "    # logging_dir=self.cfg.logging_dir,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=0.3,#self.cfg.save_steps,\n",
    "    eval_steps=0.3, #self.cfg.eval_steps,\n",
    "    save_total_limit=3,\n",
    "    gradient_accumulation_steps=3, #gradient_accumulation_steps,\n",
    "    per_device_train_batch_size=4, #train_batch_size,\n",
    "    per_device_eval_batch_size=4, #self.cfg.eval_batch_size,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    # dataloader_drop_last=True,\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=recommenderDataset(items_train),\n",
    "        eval_dataset=recommenderDataset(items_validation), #dm.datasets[DataNames.dev_language_model.value],\n",
    "        data_collator=training_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 459/3600 07:23 < 50:48, 1.03 it/s, Epoch 0.64/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and test it on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_approximate_substring(substring, string, threshold=70):\n",
    "    for i in range(len(string) - len(substring) + 1):\n",
    "        window = string[i:i+len(substring)]\n",
    "        similarity_ratio = fuzz.ratio(substring, window)\n",
    "        if similarity_ratio >= threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2557/2557 [00:07<00:00, 344.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2557\n",
      "2557\n",
      "2557\n",
      "2557\n",
      "\n",
      "number of rows: 2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_test_path = \"data/dataset_v2/testing\"\n",
    "\n",
    "user_id = []\n",
    "previous_interactions = []\n",
    "recommended_app_name = []\n",
    "turns = []\n",
    "recommend_indexes = []\n",
    "\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(conversation_test_path)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in tqdm(files):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(conversation_test_path, filename)\n",
    "\n",
    "    # Check if the current item is a file\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            file_content = file.read().lower()\n",
    "            \n",
    "            # finding the user id\n",
    "            index_1 = file_content.find(\"user's previous interactions\")\n",
    "            user_id.append(file_content[9:index_1].rstrip('\\n'))\n",
    "            \n",
    "            # finding the User's Previous Interactions\n",
    "            index_2 = file_content.find(\"recommended app name:\")\n",
    "            previous_interactions_arr = file_content[index_1+29:index_2].rstrip('\\n').split(\"app name:\")\n",
    "            previous_interactions_arr_filtered = []\n",
    "            for previous_interaction in previous_interactions_arr[1:]:\n",
    "                previous_interactions_arr_filtered.append(previous_interaction[:previous_interaction.find(\" | \")])\n",
    "            if len(previous_interactions_arr_filtered) > 0:\n",
    "                previous_interactions.append(\",\".join(previous_interactions_arr_filtered))\n",
    "            else:\n",
    "                previous_interactions.append(None)\n",
    "            \n",
    "            # finding recommended app name\n",
    "            index_3 = file_content[index_2:].find(\"package name\")\n",
    "            recommended = file_content[index_2+22:index_2+index_3-3].rstrip('\\n')\n",
    "            recommended_app_name.append(recommended)\n",
    "            \n",
    "            # finding each turns\n",
    "            dialog_turns = []\n",
    "            dialog_index = 0\n",
    "            COMPUTER_index = file_content.find(\"computer:\")\n",
    "            file_content = file_content[COMPUTER_index:]\n",
    "            found_recommender = False\n",
    "            while True:\n",
    "                HUMAN_index = file_content.find(\"human:\")\n",
    "                if HUMAN_index == -1:\n",
    "                    break\n",
    "                turn = file_content[:HUMAN_index].rstrip('\\n') # computer dialog\n",
    "                if (recommended in turn) and not found_recommender:\n",
    "                    recommend_indexes.append(dialog_index)\n",
    "                    found_recommender = True\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[HUMAN_index:]\n",
    "                \n",
    "                COMPUTER_index = file_content.find(\"computer:\")\n",
    "                turn = file_content[:COMPUTER_index].rstrip('\\n') # human dialog\n",
    "                dialog_turns.append(turn)\n",
    "                dialog_index +=1\n",
    "                file_content = file_content[COMPUTER_index:]\n",
    "                \n",
    "            if not found_recommender: # approximately finding the recommender turn\n",
    "                for i, dialog_turn in enumerate(dialog_turns):\n",
    "                    if is_approximate_substring(recommended, dialog_turn):\n",
    "                        recommend_indexes.append(i)\n",
    "                        found_recommender = True\n",
    "                        break\n",
    "                    \n",
    "            if not found_recommender:\n",
    "                recommend_indexes.append(-1)\n",
    "                        \n",
    "            turns.append(dialog_turns)\n",
    "\n",
    "print(len(user_id))\n",
    "print(len(previous_interactions))\n",
    "print(len(recommended_app_name))\n",
    "print(len(recommend_indexes))\n",
    "df_recommender_test = pd.DataFrame({\"user_id\": user_id, \"previous_interactions\":previous_interactions, \"recommended_app_name\":recommended_app_name, \"turns\": turns, \"recommend_indexes\":recommend_indexes})\n",
    "print(f\"\\nnumber of rows: {len(df_recommender_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommender_test = df_recommender_test[(df_recommender_test[\"recommend_indexes\"] != -1) & (df_recommender_test[\"turns\"].apply(lambda x: len(x) > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RecommenderItem:\n",
    "    prompt: str\n",
    "    generation: Optional[str] = None\n",
    "    \n",
    "class recommenderDataset(Dataset):\n",
    "    def __init__(self, data: List[RecommenderItem]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> RecommenderItem:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bos = '<|startoftext|>'\n",
    "eos = '<|endoftext|>'\n",
    "pad = '<|pad|>'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", bos_token=bos, eos_token=eos, pad_token=pad, additional_special_tokens=[\"computer:\", \"human:\", \"previous_interactions:\"], padding_side='left')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/GPT2_previous_interactions\").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_test = []\n",
    "for _, row in df_recommender_test.iterrows():\n",
    "    if row[\"previous_interactions\"] is not None:\n",
    "        prompt = bos + \"previous_interactions:\" + row[\"previous_interactions\"] + \"\\n\"\n",
    "    else:\n",
    "        prompt = bos + \"previous_interactions: No previous interactions\" + \"\\n\"\n",
    "    for index, turn in enumerate(row[\"turns\"]):\n",
    "        if index < row[\"recommend_indexes\"]:\n",
    "            prompt += turn + \"\\n\"\n",
    "        elif index == row[\"recommend_indexes\"]:\n",
    "            prompt += \"computer: I would recommend the \"\n",
    "            items_test.append(RecommenderItem(prompt, row[\"recommended_app_name\"] + \" app.\"))\n",
    "            break\n",
    "        else:\n",
    "            print(\"error!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(list_of_elements, batch_size): # using this chunk function, we can split our data to multiple batches\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def evaluate_recommender(dataset, model, tokenizer, batch_size=8, device=device, threshold=70):\n",
    "  prompt_arr = [data.prompt for data in dataset]\n",
    "  generation_arr = [data.generation for data in dataset]\n",
    "  prompt_batches = list(chunk(prompt_arr, batch_size))\n",
    "  generation_batches = list(chunk(generation_arr, batch_size))\n",
    "  max_length=992\n",
    "  generation_length = 32\n",
    "  correctly_predicted = []\n",
    "  for prompt_batch, generation_batch in tqdm(zip(prompt_batches, generation_batches), total = len(generation_batches)):\n",
    "\n",
    "    inputs = tokenizer(prompt_batch, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\") \n",
    "\n",
    "    generations_predicted = model.generate(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                            max_new_tokens=generation_length,\n",
    "                            num_beams=8,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id) # length_penalty=0.8, Set length_penalty to values < 1.0 in order to encourage the model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer sequences.\n",
    "\n",
    "    generations_predicted = generations_predicted[:, max_length:] # we only need the generation part, not the prompt part.\n",
    "    decoded_generations = [tokenizer.decode(generation, skip_special_tokens=True, clean_up_tokenization_spaces=True).replace(\" app.\", \"\")  for generation in generations_predicted]\n",
    "    generation_batch = [generation.replace(\" app.\", \"\") for generation in generation_batch]\n",
    "    \n",
    "    correctly_predicted.extend([1 if fuzz.ratio(predicted, ground_truth) > threshold else 0 for predicted, ground_truth in zip(decoded_generations, generation_batch)])\n",
    "\n",
    "\n",
    "  return correctly_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 634/634 [13:30<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.666403785488959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(recommenderDataset(items_test), model, tokenizer, batch_size=4, device=device, threshold=95)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/634 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 634/634 [13:30<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_rate:  0.705441640378549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correctly_predicted = evaluate_recommender(recommenderDataset(items_test), model, tokenizer, batch_size=4, device=device)\n",
    "success_rate = sum(correctly_predicted) / len(correctly_predicted)\n",
    "print(\"success_rate: \", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
